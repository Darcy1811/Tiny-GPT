{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv-ZhMEyEIsK"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets sentencepiece accelerate\n",
        "!pip install -q datasets sentencepiece\n",
        "!pip install -q datasets huggingface_hub tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RUI4tFf8aV7",
        "outputId": "61aee5d3-276c-4d47-b4e3-eb4914bf77ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKdgfvx_7rBZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import sys\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "import math\n",
        "\n",
        "# regex for words: Devanagari block + ASCII alnum fallback\n",
        "# \\u0900-\\u097F is Devanagari block; keep digits and letters as well\n",
        "word_re = re.compile(r\"[A-Za-z0-9]+|[\\u0900-\\u097F]+\")\n",
        "sentence_end_chars = set(['।', '.', '!', '?'])  # sentence separators heuristic\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyYR6KhKrdgG"
      },
      "source": [
        "**DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "16a8735f13444025a4aa46f08d5f0ce9",
            "035e583f797b40e39954c4dc2c55ee6a",
            "4705049a197f4407aa3b1ab77cbabf80",
            "e48248dce0da4f9da2f13e5dd6c8195e",
            "b7b7cee021b24dae942aecd5ae00db14",
            "78e18ad3555e4b8c971cd09d39711424",
            "e9b354f11ae64b54be98a8cba9ba7100",
            "15081eaad9644578a0d52336473f2e18",
            "f2f3ef8df2814efe85683557aad37409",
            "cafb64776dab418fa27eae0d8ef835ca",
            "3f44aaad56c3460ebaaace0af970cbf3",
            "0a3c27cdf0f546afaac6997b67fc0d93",
            "f1d777df70c649ce953cee61aad78053",
            "382b2c65e51f41828ab5029b1390fbc7",
            "f08c68002ba447b3bad4e0a7cc358d5d",
            "142460aa15a447fd9e4781cc6615e8ec",
            "2e8549966b534b9692d7da99f290fd34",
            "8f0e7ea07744469cb14847ebf9d64f62",
            "6cfd55b1fcf04440b8dde7dfe09a2289",
            "cf3f0d3ab91d4def8f1b3e45e84a9f02",
            "7f668f3bbfa845918e3418215ca6edf6",
            "3fdddf7445e945aab0578d0d990b1dfa"
          ]
        },
        "id": "kvqLqMm42siX",
        "outputId": "cf0d96eb-a9d8-474d-af05-c16aeadeeac1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16a8735f13444025a4aa46f08d5f0ce9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "data/train-00005-of-00006.parquet:   0%|          | 0.00/169M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a3c27cdf0f546afaac6997b67fc0d93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/601628 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 601628\n",
            "    })\n",
            "})\n",
            "{'text': 'समाचार-गढ़, श्रीडूंगरगढ़। श्रीडूंगरगढ़ उपखण्ड के गांव अमृतवासी में शुक्रवार को राजकीय माध्यमिक स्कूल में शिक्षकों के पद रिक्त होने के कारण छात्र-छात्राओं व अभिभावकों ने प्रदर्शन कर विरोध जताया था और रिक्त पदों पर अध्यापक लगाने की मांग की थी। आज विभाग ने इस फिलहाल कोई एक्शन लिया। जिस आज अभिभावकों व छात्रों ने स्कूल के गेट के ताला जड़ दिया है और शिक्षा विभाग के खिलाफ नारेबाजी कर रहे है। स्कूल के छात्रों का कहना है की विद्यालय में प्रधानाध्यापक का पद रिक्त है स्कूल में ६ अध्यापकों की ही नियुक्ति है इसके कारण पढ़ाई पूरी तरह प्रभावित हो रही है। ऐसे में कोर्स पूरा नहीं हो पायेगा। ग्रामीणों व अभिभावकों का कहना है की जब तक खाली पड़े अध्यापकों के रिक्त पदों पर अध्यापक को नहीं लगाया जाता जब तालाबन्दी जारी रहेगी।'}\n"
          ]
        }
      ],
      "source": [
        "# Login using: huggingface-cli login\n",
        "ds = load_dataset(\"nis12ram/nisram-hindi-text-0.0\")\n",
        "\n",
        "print(ds)\n",
        "print(ds['train'][0])     # print first sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsDOJbANrnBN"
      },
      "source": [
        "DATASET Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64TPTkG1DKAJ"
      },
      "outputs": [],
      "source": [
        "def detect_text_key(example):\n",
        "    \"\"\"\n",
        "    Given a dataset example (dict or string), return name of the text field.\n",
        "    Common keys: 'text', 'content', 'sentence'\n",
        "    If example is a string, return None (we will treat the example itself as text).\n",
        "    \"\"\"\n",
        "    if isinstance(example, str):\n",
        "        return None\n",
        "    if not isinstance(example, dict):\n",
        "        return None\n",
        "    for candidate in (\"text\", \"content\", \"sentence\", \"body\"):\n",
        "        if candidate in example:\n",
        "            return candidate\n",
        "    # fallback: choose the first string field we find\n",
        "    for k, v in example.items():\n",
        "        if isinstance(v, str):\n",
        "            return k\n",
        "    return None\n",
        "\n",
        "\n",
        "def analyze_text_iterable(iterable, text_key=None, report_every=100000):\n",
        "    \"\"\"\n",
        "    Analyze an iterable of text examples:\n",
        "      - iterable yields either plain strings or dict-like examples with a text field\n",
        "      - text_key: if provided, used as the key to extract text from examples\n",
        "    Returns a stats dict.\n",
        "    \"\"\"\n",
        "    char_count = 0\n",
        "    word_count = 0\n",
        "    unique_chars = set()\n",
        "    vocab_counter = Counter()\n",
        "    sentence_count = 0\n",
        "    char_freq = Counter()\n",
        "\n",
        "    # If the iterable is a datasets.IterableDataset, it yields examples one by one.\n",
        "    # If it's a list or arrow table, it will also work.\n",
        "    it = iter(iterable)\n",
        "    # If text_key is None we try to auto-detect using the first example (but then must re-run it).\n",
        "    first_example = None\n",
        "    try:\n",
        "        first_example = next(it)\n",
        "    except StopIteration:\n",
        "        # empty iterable\n",
        "        return {\n",
        "            \"char_count\": 0, \"word_count\": 0, \"unique_chars_count\": 0,\n",
        "            \"vocab_size\": 0, \"sentence_count\": 0, \"top_tokens\": [], \"top_chars\": []\n",
        "        }\n",
        "\n",
        "    if text_key is None:\n",
        "        text_key = detect_text_key(first_example)\n",
        "\n",
        "    # helper to extract string from an example\n",
        "    def get_text(ex):\n",
        "        if isinstance(ex, str):\n",
        "            return ex\n",
        "        if text_key is None:\n",
        "            # try to convert the example to string (best-effort)\n",
        "            return str(ex)\n",
        "        return ex.get(text_key, \"\") if isinstance(ex, dict) else str(ex)\n",
        "\n",
        "    # process first example\n",
        "    examples_processed = 0\n",
        "    for ex in [first_example]:\n",
        "        text = get_text(ex) or \"\"\n",
        "        char_count += len(text) + 1  # include newline-like count to match original script behaviour\n",
        "        unique_chars.update(text)\n",
        "        char_freq.update(text)\n",
        "        words = word_re.findall(text)\n",
        "        word_count += len(words)\n",
        "        if words:\n",
        "            vocab_counter.update(words)\n",
        "        for ch in sentence_end_chars:\n",
        "            sentence_count += text.count(ch)\n",
        "        examples_processed += 1\n",
        "\n",
        "    # process the rest\n",
        "    for i, ex in enumerate(it, start=1):\n",
        "        text = get_text(ex) or \"\"\n",
        "        char_count += len(text) + 1\n",
        "        unique_chars.update(text)\n",
        "        char_freq.update(text)\n",
        "        words = word_re.findall(text)\n",
        "        word_count += len(words)\n",
        "        if words:\n",
        "            vocab_counter.update(words)\n",
        "        for ch in sentence_end_chars:\n",
        "            sentence_count += text.count(ch)\n",
        "        examples_processed += 1\n",
        "        if examples_processed % report_every == 0:\n",
        "            print(f\"Processed {examples_processed} examples... (words so far: {word_count})\", file=sys.stderr)\n",
        "\n",
        "    unique_chars_count = len(unique_chars)\n",
        "    vocab_size = len(vocab_counter)\n",
        "\n",
        "    stats = {\n",
        "        \"char_count\": char_count,\n",
        "        \"word_count\": word_count,\n",
        "        \"unique_chars_count\": unique_chars_count,\n",
        "        \"vocab_size\": vocab_size,\n",
        "        \"sentence_count\": sentence_count,\n",
        "        \"top_tokens\": vocab_counter.most_common(50),\n",
        "        \"top_chars\": char_freq.most_common(50),\n",
        "        \"examples_processed\": examples_processed\n",
        "    }\n",
        "    return stats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZxBWzl9rvS5"
      },
      "source": [
        "Example of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMc3fsj8DnEU",
        "outputId": "6ac991bd-bd17-4535-fb2c-47f4091eb96e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 601628\n",
            "    })\n",
            "})\n",
            "First example: {'text': 'समाचार-गढ़, श्रीडूंगरगढ़। श्रीडूंगरगढ़ उपखण्ड के गांव अमृतवासी में शुक्रवार को राजकीय माध्यमिक स्कूल में शिक्षकों के पद रिक्त होने के कारण छात्र-छात्राओं व अभिभावकों ने प्रदर्शन कर विरोध जताया था और रिक्त पदों पर अध्यापक लगाने की मांग की थी। आज विभाग ने इस फिलहाल कोई एक्शन लिया। जिस आज अभिभावकों व छात्रों ने स्कूल के गेट के ताला जड़ दिया है और शिक्षा विभाग के खिलाफ नारेबाजी कर रहे है। स्कूल के छात्रों का कहना है की विद्यालय में प्रधानाध्यापक का पद रिक्त है स्कूल में ६ अध्यापकों की ही नियुक्ति है इसके कारण पढ़ाई पूरी तरह प्रभावित हो रही है। ऐसे में कोर्स पूरा नहीं हो पायेगा। ग्रामीणों व अभिभावकों का कहना है की जब तक खाली पड़े अध्यापकों के रिक्त पदों पर अध्यापक को नहीं लगाया जाता जब तालाबन्दी जारी रहेगी।'}\n"
          ]
        }
      ],
      "source": [
        "# Non-streaming: loads the dataset into memory (fine for small datasets)\n",
        "ds = load_dataset(\"nis12ram/nisram-hindi-text-0.0\")   # you already used this\n",
        "print(ds)  # shows splits\n",
        "# choose the split you want (commonly 'train')\n",
        "train = ds['train']\n",
        "# If needed, peek at a few examples to find the text key\n",
        "print(\"First example:\", train[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smUmb1BvDrNr",
        "outputId": "96476423-2275-424f-e029-a9dbc262e44d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed 50000 examples... (words so far: 17274883)\n",
            "Processed 100000 examples... (words so far: 34501909)\n",
            "Processed 150000 examples... (words so far: 51763808)\n",
            "Processed 200000 examples... (words so far: 68989346)\n",
            "Processed 250000 examples... (words so far: 86230533)\n",
            "Processed 300000 examples... (words so far: 103423042)\n",
            "Processed 350000 examples... (words so far: 120614974)\n",
            "Processed 400000 examples... (words so far: 137877409)\n",
            "Processed 450000 examples... (words so far: 155170879)\n",
            "Processed 500000 examples... (words so far: 172335751)\n",
            "Processed 550000 examples... (words so far: 189593572)\n",
            "Processed 600000 examples... (words so far: 206789121)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Corpus Statistics ===\n",
            "Examples processed: 601628\n",
            "Total Characters (approx): 1056798944\n",
            "Total Words (approx): 207350821\n",
            "Unique Characters: 1756\n",
            "Unique Words (Vocabulary Size): 1786730\n",
            "Estimated Sentences (by punctuation counts): 11478613\n",
            "\n",
            "Top 30 tokens:\n",
            "के : 8190662\n",
            "में : 6070115\n",
            "की : 4711155\n",
            "को : 3668388\n",
            "से : 3607895\n",
            "और : 3142771\n",
            "है : 3121363\n",
            "का : 2779945\n",
            "है। : 2747717\n",
            "ने : 2263257\n",
            "पर : 2172964\n",
            "कि : 1715033\n",
            "भी : 1595443\n",
            "लिए : 1517075\n",
            "एक : 1398161\n",
            "इस : 1229166\n",
            "हैं : 1206286\n",
            "कर : 1128838\n",
            "हैं। : 1085297\n",
            "नहीं : 1031824\n",
            "ही : 959952\n",
            "किया : 874835\n",
            "हो : 846742\n",
            "करने : 843516\n",
            "यह : 822438\n",
            "साथ : 820113\n",
            "तो : 777459\n",
            "गया : 617017\n",
            "कहा : 615047\n",
            "अपने : 583809\n",
            "\n",
            "Top 30 characters:\n",
            "' ' : 202198595\n",
            "'ा' : 68857840\n",
            "'क' : 57673098\n",
            "'र' : 54988828\n",
            "'े' : 51847815\n",
            "'्' : 38753773\n",
            "'न' : 34333266\n",
            "'स' : 33892483\n",
            "'ि' : 33130411\n",
            "'ी' : 32932587\n",
            "'ं' : 30156437\n",
            "'ह' : 28511341\n",
            "'म' : 26931342\n",
            "'त' : 24910975\n",
            "'ल' : 23215290\n",
            "'ो' : 22446948\n",
            "'प' : 21752610\n",
            "'य' : 19653527\n",
            "'व' : 16456920\n",
            "'द' : 15026373\n",
            "'ज' : 14267031\n",
            "'ब' : 13027578\n",
            "'ग' : 12358342\n",
            "'ै' : 11532519\n",
            "'ु' : 10582085\n",
            "'ट' : 9273299\n",
            "'।' : 8402648\n",
            "'ए' : 7925914\n",
            "'श' : 7859271\n",
            "'अ' : 6655969\n",
            "Saved stats to corpus_stats.json\n"
          ]
        }
      ],
      "source": [
        "# If the split is a Dataset (not streaming), it is indexable and iterable\n",
        "# If the dataset examples are dicts, the analyzer will auto-detect the text field\n",
        "stats = analyze_text_iterable(train, text_key=None, report_every=50000)\n",
        "\n",
        "# Pretty-print core results\n",
        "print(\"=== Corpus Statistics ===\")\n",
        "print(f\"Examples processed: {stats['examples_processed']}\")\n",
        "print(\"Total Characters (approx):\", stats['char_count'])\n",
        "print(\"Total Words (approx):\", stats['word_count'])\n",
        "print(\"Unique Characters:\", stats['unique_chars_count'])\n",
        "print(\"Unique Words (Vocabulary Size):\", stats['vocab_size'])\n",
        "print(\"Estimated Sentences (by punctuation counts):\", stats['sentence_count'])\n",
        "\n",
        "# Top tokens\n",
        "print(\"\\nTop 30 tokens:\")\n",
        "for tok, cnt in stats['top_tokens'][:30]:\n",
        "    print(f\"{tok} : {cnt}\")\n",
        "\n",
        "print(\"\\nTop 30 characters:\")\n",
        "for ch, cnt in stats['top_chars'][:30]:\n",
        "    print(f\"{repr(ch)} : {cnt}\")\n",
        "\n",
        "# Save stats to JSON for later use\n",
        "with open(\"corpus_stats.json\", \"w\", encoding=\"utf-8\") as out:\n",
        "    json.dump(stats, out, ensure_ascii=False, indent=2)\n",
        "print(\"Saved stats to corpus_stats.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29gFUUqGJH-d",
        "outputId": "945a69f7-4e8a-4790-ec8d-e5d6a9512dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-noto-ui-core\n",
            "The following NEW packages will be installed:\n",
            "  fonts-noto-core fonts-noto-hinted fonts-noto-ui-core fonts-noto-unhinted\n",
            "0 upgraded, 4 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 13.6 MB of archives.\n",
            "After this operation, 48.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-core all 20201225-1build1 [12.2 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-ui-core all 20201225-1build1 [1,420 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto-hinted all 20201225-1build1 [3,988 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-noto-unhinted all 20201225-1build1 [16.8 kB]\n",
            "Fetched 13.6 MB in 2s (7,359 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-noto-core.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-noto-core_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-core (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-ui-core.\n",
            "Preparing to unpack .../fonts-noto-ui-core_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-ui-core (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-hinted.\n",
            "Preparing to unpack .../fonts-noto-hinted_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-hinted (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-unhinted.\n",
            "Preparing to unpack .../fonts-noto-unhinted_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-unhinted (20201225-1build1) ...\n",
            "Setting up fonts-noto-unhinted (20201225-1build1) ...\n",
            "Setting up fonts-noto-ui-core (20201225-1build1) ...\n",
            "Setting up fonts-noto-core (20201225-1build1) ...\n",
            "Setting up fonts-noto-hinted (20201225-1build1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install fonts-noto-core fonts-noto-hinted fonts-noto-unhinted -y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZU84pL7zJWsI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.font_manager as fm\n",
        "for f in fm.findSystemFonts():\n",
        "    if \"Devanagari\" in f:\n",
        "        print(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Un6kDIXIcz7",
        "outputId": "1c9bb23c-1cf6-49d8-ba84-ef9970d58657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Font not found. Using default.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# Find Devanagari font installed\n",
        "font_paths = [f for f in fm.findSystemFonts() if \"NotoSansDevanagari\" in f or \"Noto Serif Devanagari\" in f]\n",
        "\n",
        "if font_paths:\n",
        "    devanagari_font = font_paths[0]\n",
        "    print(\"Using:\", devanagari_font)\n",
        "else:\n",
        "    print(\"Font not found. Using default.\")\n",
        "\n",
        "plt.rcParams['font.family'] = 'Noto Sans Devanagari'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDwz5P8PIcvP",
        "outputId": "ebac2a73-9433-48fb-ccd0-7dd2649a3f90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2375 (\\N{DEVANAGARI VOWEL SIGN E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2381 (\\N{DEVANAGARI SIGN VIRAMA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2360 (\\N{DEVANAGARI LETTER SA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2361 (\\N{DEVANAGARI LETTER HA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2350 (\\N{DEVANAGARI LETTER MA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2354 (\\N{DEVANAGARI LETTER LA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2346 (\\N{DEVANAGARI LETTER PA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2351 (\\N{DEVANAGARI LETTER YA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2357 (\\N{DEVANAGARI LETTER VA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2332 (\\N{DEVANAGARI LETTER JA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2348 (\\N{DEVANAGARI LETTER BA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2376 (\\N{DEVANAGARI VOWEL SIGN AI}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2404 (\\N{DEVANAGARI DANDA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2319 (\\N{DEVANAGARI LETTER E}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2358 (\\N{DEVANAGARI LETTER SHA}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/tmp/ipython-input-66691623.py:9: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2375 (\\N{DEVANAGARI VOWEL SIGN E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2381 (\\N{DEVANAGARI SIGN VIRAMA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2360 (\\N{DEVANAGARI LETTER SA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2361 (\\N{DEVANAGARI LETTER HA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2350 (\\N{DEVANAGARI LETTER MA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2354 (\\N{DEVANAGARI LETTER LA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2346 (\\N{DEVANAGARI LETTER PA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2351 (\\N{DEVANAGARI LETTER YA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2357 (\\N{DEVANAGARI LETTER VA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2342 (\\N{DEVANAGARI LETTER DA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2332 (\\N{DEVANAGARI LETTER JA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2348 (\\N{DEVANAGARI LETTER BA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2376 (\\N{DEVANAGARI VOWEL SIGN AI}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2335 (\\N{DEVANAGARI LETTER TTA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2404 (\\N{DEVANAGARI DANDA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2319 (\\N{DEVANAGARI LETTER E}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2358 (\\N{DEVANAGARI LETTER SHA}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "/usr/local/lib/python3.12/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 2309 (\\N{DEVANAGARI LETTER A}) missing from font(s) DejaVu Sans.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Noto Sans Devanagari' not found.\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAHqCAYAAAB/bWzAAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVOpJREFUeJzt3Xl4FeXdP/5P2BIQEkSEgLK6IZZNVEStuKABKRZFBLQV0Wpr3XHFqmirRa0L+mi1tSra1qLWrS5f1FLRWnEDqVWrj/pAQTYRMQFUULh/f/jLqTEJErYM+Hpd11xtZu6Zec/JOSfyzp05eSmlFAAAAAAAZEKd2g4AAAAAAMB/KW0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyBClLQAAAABAhihtAWAjysvLq/Gy33771XbsiIi48cYbY+jQodG5c+do3rx51K9fP5o1axb77rtv3HTTTfH555+vdv/77rsv9ttvv9hyyy1jiy22iG7dusVVV131jft9k9mzZ8eFF14Ye+65Z2y99dZRv379aNq0aey6665x+umnx8svv1xh/MyZMyMvLy/at2+/TuclG+bOnRtNmjSJgQMHVlhf/n3+6lK3bt1o2rRpdOzYMQYOHBi//OUv4z//+U8tJWd9ad++feTl5cXMmTPXeJ9LLrnkG997u3fvvsEyb2jlj8nqlnHjxkVExH777Rd5eXkxefLkWs1cnfHjx0deXl4ce+yxFdb/4Q9/iLy8vPj1r39dO8EAYAOrV9sBAODbZMSIEZXWzZ8/P5544olqt3fq1GmD51oTV1xxRSxYsCB22WWX6NWrVxQWFsacOXNiypQp8fe//z1+//vfx1//+tdo3LhxpX3POOOMuP7666NevXpxwAEHROPGjeNvf/tbnHfeefHII4/Ek08+GQ0bNqxxpquuuiouuuiiWLFiRTRu3Dh69eoVLVq0iCVLlsS//vWvuOGGG+KGG26Ic845J6666qr18TBs0mbOnBkdOnSIdu3a1ajgyrJzzjknPvnkk/jlL39Z7ZjBgwfnnpdLliyJefPmxV//+td49NFH48ILL4wTTzwxrr766iqfu2zeWrZsGf369atyW9u2bTdymv/ab7/94plnnomnn356nX5xt/fee8f2229f5bbOnTuv9XGz4Kijjsr9DBg2bFg0a9astiMBwHqltAWAjWj8+PGV1k2ePDlX2la1PSsmTJgQ3bt3r1RszZo1Kw4++OB48cUX4/LLL4+xY8dW2P7QQw/F9ddfH40bN45nnnkmdt1114iI+PDDD+OAAw6I5557Li666KK4+uqra5Tn/PPPjyuvvDLq168fV199dZxyyimRn59fYcwLL7wQP/vZz+J///d/1+KKybqXX3457r777hgyZEh06dKl2nFXX311pZnVn376adxxxx1x/vnnx29+85t4880346mnnqr0HCL7Jk2aFJ9//nlss802Nd63U6dOmX7fXVc/+tGPKs1Q/bq77rorPvnkk1otqddGnTp1YsyYMXHEEUfEZZddFtdee21tRwKA9crtEQCANbLPPvtUOROxbdu28bOf/SwiIp588slK28tnQJ5//vm5wjYionnz5rk/a73xxhujtLR0jbNMmjQprrzyyoiIuOeee+Kss86qsmzbc889469//WucddZZa3xsNh3lf959/PHH13jfhg0bxk9/+tOYPHlyFBQUxN///nezsTdR2223XXTq1Cnq169f21E2SW3bto1OnTpFo0aNajtKjR166KGx9dZbx2233RZLly6t7TgAsF4pbQEg495///049dRTY4cddoiCgoIoKiqKvffeO37zm9/EypUrK43/6v3/Fi1aFCeffHK0bds28vPzo127dnHmmWfG4sWL12vGevW+/OOdrxenc+bMyd1T9qijjqq03z777BNt2rSJ5cuXx+OPP77G57vssssi4st/sB922GGrHZuXlxff/e53q9yWUorf/va30bNnz9hiiy2iqKgoDj744JgyZUqV41966aU499xzY4899oji4uJo0KBBtGzZMgYOHBh//etfq9znq9+Pjz76KM4444zYbrvtIj8/v8KfPf/1r3+NU089Nbp37x7NmzeP/Pz82HbbbWPo0KGV7sv7dVOnTo0RI0ZEhw4doqCgIJo1axbdunWLc845J3fP1mOPPTY6dOgQERH/+c9/Kt3fsqpjHn300bnnTrNmzaKkpKTa79NX7yv68MMPxwEHHBDNmjWrcK/M5cuXx69+9avo2bNnNGnSJBo0aBDFxcWx++67x7nnnhsfffTRaq/zqxYsWBB//vOfo3Xr1nHQQQet8X5ft+uuu8app54aERHXXXddfPHFF5XGLF68OMaMGRPdu3ePJk2aRKNGjaJLly5x2WWXxSeffFJh7PDhwyMvLy+uuOKKas/56KOPRl5eXvTo0SO37vPPP48//OEPcfTRR0enTp2isLAwGjZsGDvttFOcdtppMXfu3CqP9dX7kU6fPj0OP/zw3POnc+fOcc0110RKqdJ+CxcujBtuuCEOOeSQ6NChQzRs2DAKCwtjt912iyuvvDI+++yzavO//vrrMXjw4GjevHnusRg3blysWrWq2vvLvvnmmzFmzJjYe++9Y5tttokGDRrEVlttFX379o177723yvNMnjw5d1/vTz75JC6++OLYeeedo1GjRhVmTq/NPW3XxhdffBG33HJL7LXXXlFUVBQFBQWxww47xGmnnRZz5sypcp+vvr7uv//+2GeffaKwsDC22GKL2HvvvSu9nsqv+ZlnnomIiP3337/C63RDzAqu6p62L7zwQjRo0CAaNmwY06dPr7TPa6+9Fo0aNYr69evHP/7xjwrbavJ6KffFF1/EuHHjokuXLlFQUBBbb711DB48OP71r3+tNnv9+vXjqKOOirKysvj9739f42sHgExLAECtevrpp1NEpKp+LL/00kupWbNmKSJS27Zt09ChQ1O/fv1SQUFBiohUUlKSli9fXmGfO+64I0VEOvTQQ9N2222XmjZtmgYNGpQOO+ywtOWWW6aISDvttFP64IMP1kv+BQsWpG7duqWISGPHjq2w7ZFHHkkRkZo1a1bt/ocddliKiHTOOees0fkWL16c6tSpkyIi3X///TXOO2PGjBQRqV27dmnEiBGpfv366YADDkhHHnlk2nHHHVNEpPz8/PTCCy9U2vfAAw9MderUSV26dEmHHHJIGjJkSNp1111z379x48ZV2qf8+zFgwIDUoUOHtOWWW6ZDDz00DRkyJB199NG5cdttt11q0KBB6tGjRzr00EPT4Ycfnjp37pwiItWrVy/9+c9/rvJ6rrrqqtzjseOOO6YjjzwyDRw4MO28884pItIdd9yRUkrp1ltvTYMHD04RkbbYYos0YsSICstXjRs3LnfM7t27pyOOOCLts88+qUGDBiki0qWXXlopR7t27VJEpFNOOSVFRNptt93S8OHDU58+fdKzzz6bVq5cmQ488MAUEamwsDD1798/DR8+PPXt2ze376uvvrrG38fbb789RUT6wQ9+UOX28u9zRKQZM2as9lj//Oc/c2OnTJlSYdsbb7yR2rRpkyIitWrVKvXr1y8NHDgwtWzZMvf4fPzxx7nxTzzxRIqI1KlTp2rPd/jhh6eISDfccENu3ezZs1NEpKKiorTnnnumIUOGpEMOOSS1bt06RUTaeuut0zvvvFPpWH369EkRkc4///zUoEGDtPPOO6dhw4alPn36pLp166aISKeffnql/X7/+9+niEjbbLNN6tOnTxo2bFg68MADU+PGjVNEpN69e6fPPvus0n6TJ09ODRs2TBGRtttuuzRs2LB00EEHpQYNGqShQ4fmvpdff8yPP/743ONSUlKShg4dmnr37p17np155pmVzlX+3tirV6+0++67py222CL1798/DR06NPXt2zc3rrpzrs6YMWNSRKQ+ffqs0fjPPvss9e3bN0VEKigoyOUof240b948TZ06tdJ+5c+riy++OOXl5aW99947DR06NPeemZeXlx544IHc+H//+99pxIgRuedXSUlJhdfp3//+9zXKW/6YlL/+V6f8OfT0009XWH/NNdekiEg77LBDKisry60vKyvLvVdeddVVFfap6eslpZRWrlyZBg0alCIiNWjQIB188MFp6NChqX379qmgoCD99Kc/TRFR6X2q3KOPPpoiIh188MFr9NgAwKZCaQsAtay60vazzz7L/cP7Jz/5SVqxYkVu23vvvZfat2+fIiJdcMEFFfYrLwkjIu25555p0aJFuW2LFy9Oe+21V4qINGzYsLXK+8c//jGNGDEiHX300emAAw5I+fn5uX9Qf71AvuGGG3L/UK/OaaedliIiHXHEEWt0/kmTJuWub9asWTXO/9Uyr127duntt9/Obfviiy/ScccdV20B8Pjjj6e5c+dWWv/888+nwsLCVL9+/fT+++9X2PbV78eBBx6YSktLq8z14IMPpo8++qjK9fXq1UtbbbVV+uSTTypse/jhh3Ml0j333FNp3zfeeCO9+eabla69Xbt2VWZIKaWJEyemvLy81Lx58/TMM89U2Pbaa6+lbbfdNkVEmjx5coVt5c/VunXrpocffrjScZ955pkUEalHjx4VCqByL7/8cvrwww+rzfV1P/jBD1JEpJtuuqnK7TUpbVeuXJkrpH/3u9/l1n/yySdpu+22SxGRLrzwwgrP72XLlqXhw4eniEgjR46scKy2bdtWWQCnlNLChQtT/fr1U4MGDSpcb1lZWXr44YcrvYZWrFiRRo8enSIiHXLIIZWOV164RUS65ZZbKmybNGlSysvLS3Xr1k2zZ8+usO3NN9+sMt9HH32UDj744CoLuU8++SRts802KSLSWWedlVauXJnb9sYbb+SKuaoe88mTJ6f33nuv0vneeuut3HPqxRdfrLDtq++NXbt2TfPmzau0f0obp7Q977zzckX1V8+zYsWKXCHdoUOHSt+/8vxNmzat9Iug8gw77rhjpfNVV6SuqfVR2qaUcmXqV39eDBs2LEVE+t73vpdWrVqVW782r5eUUrrxxhtTRKSWLVtWeL/6/PPP00knnZR7DKsrbRctWpTy8vJSo0aNKj3+ALApU9oCQC2rrrQtnwnXunXrKme8/fnPf04RkZo0aZI+/fTT3PqvloRVzVx87bXXUl5eXqpTp06lImdNnH766bnjl88UO/PMMyvNnkoppcsvvzxFRNp7772rPd4FF1xQo1lSEyZMyJ27qsflm3y1zPvLX/5Safu8efNys22/WpR/k/Ji7eslYvn3o379+lWWVmuivOx47LHHKqzv3r17ioh0zTXXrNFx1qS07dWrV4qIamf23nvvvSki0uDBgyusLy+JjjvuuNXud9ppp61R1m+yyy67pIhIf/vb36rcXpPSNqWUiouLU0SkK6+8Mrfu5ptvzpVTVVmyZElq0aJFqlevXoXC/aKLLkoRkU488cRK+4wbN65Gv6Qo17p161SnTp1KhXd54Xb44YdXuV+/fv1SRKS77rprjc/19ttvp4hIu+++e4X1d911V+75U9Vro7x8q2mB+pvf/CZFVJ5t/9X3xmeffbba/deltF3dUn68Tz/9NDcDuar3jGXLluUK6z/+8Y8VtpUf66uzqst99tlnqaioqMpfQK2v0ra65atl9erOtXjx4tShQ4cUEenXv/51+vWvf50ivvzLj6/+QjCltX+9bL/99iki0s0331xpn08//TT32qyutE0ppVatWqWISP/85z9X/8AAwCbkyxvQAQCZU35/wWHDhlX5IVuHH354bLnllrF48eKYOnVq7L333hW2d+vWLbp3715pvy5dukSPHj1i2rRp8eyzz1Z5r9nVGTduXIwbNy6WL18eM2fOjD/84Q9xzTXXxAMPPBCPP/54dO7cuUbHqy316tWLfv36VVpfXFyce1wXLVoUxcXFFbYvWrQoHnvssXj99ddj8eLF8fnnn0dExDvvvBMREW+//XaV5+vRo0d07NhxtZnmzp0bjz32WLz11ltRWlqau7/qG2+8kTv2IYccEhER8+fPj+nTp0edOnXW6oO4qvLhhx/GSy+9FA0bNoyBAwdWOab8PrzPP/98lduPOOKIKtfvuuuuUbdu3bj99ttjxx13jMMPPzxatWq11lkXLFgQERFbbbXVWh/jq1atWhURUeH+vo899lhERAwdOrTKfRo3bhy77bZbPP744/Hyyy/HwQcfHBFf3j/4sssui3vuuSfGjRsXDRs2zO1zxx13RETEcccdV+Ux//nPf8akSZNixowZsWzZslyuL774IlatWhXvvvtuhXvhlqvu+7XzzjvHxIkTq7zn6sqVK2Py5Mnx/PPPx7x58+LTTz+N9OWkjoio/Fwuv8/qkCFDqvzQr6OPPjpOOeWUKnNERCxdujT+3//7f/Hqq6/Ghx9+GCtWrIiIiHnz5lV5vnItWrSo9r7U66ply5ZVvg9ERO6DF1955ZVYunRpNGvWrMrHuVGjRjFs2LC4/vrr4+mnn67yPbWq/fLz86Njx47x6quvxpw5c6JNmzbreDWV7b333rH99ttXWt+pU6c12r9p06Zx7733xt577x1nnnlmRHx5H9l77703mjVrVmHs2rxe5syZE++++25ERPzgBz+otE9BQUEceeSRccMNN6w251ZbbRXz5s3LvS8AwOZAaQsAGVVespR/eNTX5eXlRYcOHWLx4sVVFjLV7Ve+bdq0afH++++vdb78/PzYaaed4he/+EV07do1jjzyyBgxYkSFD81q0qRJREQsW7as2uOUf+J3YWHhGp136623zv3/Dz74YK2LjlatWlX7afOFhYWxePHiSh/GdOutt8aZZ5652uspKyurcv1XPzipKpdeemlcfvnluRL4m449a9asiPjyOoqKilZ77DU1Y8aMSCnFp59+WuUvCr5q4cKFVa6v7jq32267uO666+Kcc86JU045JU455ZRo165d9O7dO773ve/FkCFDokGDBmuctbS0NCLW/HmzOitXroyPP/44IqJCEfV///d/ERHxwx/+MH74wx+u9hhffTw6duwYffr0icmTJ8eDDz6YK/FeffXV+Oc//xmtW7fOFbzlli1bFj/84Q/jwQcfXO15qnt+tW3btsr15Y/P15/L77zzThx22GG5XwisybnK3y+q+x43bdo0ioqKct+br3rkkUdi5MiRsWjRojU+X7lveu2si06dOn3jh3t903txxJfP76+O/bqafn/Wlx/96Edx7LHHrtMxdttttxgzZkz87Gc/i4iIK6+8Mnr16lVp3Nq8XsqfU82bN8+V5F+3use9XPnjuL4/ZBMAatNmV9o+++yz8atf/SqmTp0a8+bNiwcffDAGDRpUo2M88cQTMWbMmHjjjTeioKAg9t1337jmmms26H8wAkBtKJ9Rt64GDx4cTZo0iVdeeSVmz56dK1LLf3bOnj272n3Lt63pz9kePXpEnTp1YtWqVfHyyy+vdWlbp06dGo2fOnVq/PjHP466devGlVdeGQMHDoy2bdtGo0aNIi8vL37729/Gj3/842of06/Otvy6Bx54IC655JJo3Lhx3HjjjXHAAQdE69ato2HDhpGXlxcXXHBBjB07dr19v6pTPquzcePGMXjw4LU6xuqu89RTT40jjzwy/vKXv8Rzzz0Xzz33XEyYMCEmTJgQY8aMib///e9rPPu2adOmsXDhwmqLvpp4/fXXc7M+u3Tpkltf/nj069cvWrZsudpjtGvXrsLXxx13XEyePDnGjx+fK23LZ9kec8wxUbdu3QrjR48eHQ8++GB06tQprrjiith9992jefPmuSJ7r732iilTplT7HKjp8/mII46IN954I773ve/FueeeG507d47CwsKoX79+rFixYrWl/VdnI6/Jtjlz5sTQoUPj008/jXPPPTeOPvroaN++fTRu3Djq1KkTTz75ZJSUlKzVa2dTUdPvT5Z89tlncd999+W+fvHFF6scty6vl3VV/ouCLbfccr0eFwBq02ZX2i5btiy6desWxx13XBx++OE13n/GjBnx/e9/P0aNGhV//OMfo7S0NM4888w4/PDDY9q0aRsgMQBUbZtttomI/85eqsqMGTMqjK1qW1VmzpwZERHbbrvtOiT8rzp16kTDhg1jyZIlFWa/lv8Z96JFi2LGjBlVzph65ZVXIuLLP59fE1tuuWV897vfjWeeeSbuvPPOtfp5vzbuu+++SCnFqaeeGueee26l7eW3R1gb9957b0REXH755XHiiSeu0bHLZ+7NmzcvSktL18ts2/LvW15eXtx+++0bpGhq2bJlnHDCCXHCCSdERMRbb70Vxx13XEyZMiXOP//8uPPOO9foOC1atIiFCxeudubmmvrDH/4QEV/+iXXPnj1z69u0aRNvvfVWHH/88dXe9qE6gwcPjlNOOSUmTZoUs2fPjpYtW8bdd98dEREjR46sNL78OXDPPfdE165dK21fl+fX17311lvx2muvRYsWLeLBBx+MevUq/pOgunOVv8+Uv398XWlpaW7G8lc98sgj8emnn8Zhhx0WV155ZaXt6/PaNoTy617de2r5+3RV78WbujPOOCOmT58effr0iffffz8eeOCBuOGGG+K0006rMG5tXi/lj9eHH34YS5curXK2bXXPt68qfx/4prIYADYlm+6vfKvRv3//uOyyy+Kwww6rcvvy5cvj7LPPjm222Sa22GKL6NWrV+6egRFfzqJZuXJlXHbZZbHddtvFrrvuGmeffXZMnz59tX+uCADrW/m9Q++5554q/3T2wQcfjMWLF0eTJk0qFE3lXnvttXjttdcqrX/jjTdi2rRpUadOndh3333XS9bXX389Pvjgg6hbt26F+7Zuu+22sfvuu0dE5Aqrr3ruuedi9uzZkZ+fn7tX65oo/zPdv/zlL9/45+QppXjuuefW+NjV+eijjyKi6hlin332Wdx///0b5NgffPBBPPXUU5XWFxcXR7du3WLVqlVx++23r9F5ymdtlt8r9+tat24dXbt2jSVLlsTEiRPXNP466dSpU5x33nkRETF9+vQ13q+85H/zzTfX6fzTpk2LG2+8MSIiRo0aVWEGbP/+/SPiv4VqTTRq1CiGDh0aq1atirvuuiseeeSRWLRoUey9996x4447Vhq/uufAE088ER9++GGNM1Sn/FytW7euVNhG/LfE/rry94v77ruvyudQVa/xr56vqmtLKVW7X1bstttu0bhx4/joo4/iL3/5S6Xtn376aUyYMCEiIvbff//1cs5veq1uLH/605/iN7/5TbRs2TImTJgQ9957b+Tn58c555yT+4VbubV5vWy77ba5nxlVPQ+WL19eYZZvVRYtWhTz58+PRo0axc4777zG5waArNvsSttvcsopp8SUKVNiwoQJ8dprr8WQIUOiX79+ud/w9+zZM+rUqRN33HFHrFy5MkpLS+P3v/999O3bt9r73gHAhjBkyJBo27ZtzJ07N0aNGlXhH+8zZsyIs846KyK+/JPzgoKCSvunlOKkk06qcI+/0tLSOOmkkyKlFIMHD17jWws899xz8cgjj1RZIEybNi2GDx+ey/z1P0+94IILIiLiiiuuqPBXK4sWLYqf/vSnEfHlz+eazBQ96KCDctc/bNiwuPbaa2P58uWVxk2dOjVKSkri6quvXuNjV6e8DLjzzjtjyZIlufWfffZZ/PSnP13tLLw1PfZvf/vb3J/pR3z5/RoxYkSV9wiNiBgzZkxEfFliV1Uav/nmm/Hvf/879/XWW28dDRo0iPnz5+eKtK+77LLLIuLL2aCPPPJIpe0ppXjxxRfjySefXMOr+9Lf/va3ePzxxyv9EjylFI8++mhE1OxPpsvLsSlTptQoR7lPP/00br755thvv/3is88+i/322y/OPvvsCmNOPPHEaNeuXdx3331x3nnnVfi+l5s/f37ceuutVZ6j/MPGxo8fnyvWq5plG/Hf58D//M//VFj/9ttvx09+8pOaXdw32HHHHaNu3brxr3/9q8LkhYgvZ8Ved911Ve43ZMiQaNWqVcycOTN+9rOf5f4cPuLL2bs///nPq9yv/Nr+/Oc/5z50LOLLewlffPHF1X6oXVYUFBTEySefHBERZ511VvznP//Jbfv888/j9NNPj/nz50eHDh1qPCO7OuV/BbG6ew5vaG+//XaceOKJUadOnfjjH/8YxcXFseuuu8Y111wTK1asiCOPPLLCzOq1fb2cccYZERFxySWXxFtvvZVbv3Llyjj77LNj7ty5q81Z/vzZZ599/HsNgM1L2oxFRHrwwQdzX//nP/9JdevWTXPmzKkw7sADD0yjR4/OfT158uTUokWLVLdu3RQRqXfv3mnx4sUbKTUA3zZPP/10iohU1Y/ll156KTVr1ixFRGrXrl0aOnRoOuSQQ1JBQUGKiFRSUpKWL19eYZ877rgjRUQ69NBDU8eOHVPTpk3TYYcdlg4//PDcsXbYYYe0YMGCNc5YfsymTZum/fffPx111FHp0EMPTV26dMll33vvvav9eXnaaaeliEj169dP/fr1S4MHD05NmzbN7ffJJ5/U6DErd/nll6f69euniEhNmjRJffv2zWVr3759Ltt5552X22fGjBm5x7M67dq1SxGRZsyYkVu3ePHi3PqtttoqDRo0KA0ePDi1aNEiNWnSJJ1++ukpItKIESOqfOy+vv6r/u///i/3eGyzzTZp8ODB6dBDD01FRUWpVatW6bjjjksRkcaMGVPlY5CXl5ciInXq1CkNHTo0HXrooalz584pItIdd9xRYfwRRxyRIiK1adMmDR8+PB1//PHp+OOPrzDm+uuvT/Xq1UsRkbbffvs0YMCAdNRRR6WDDjootWjRotJjWt1j9lXXXXddiohUWFiY9ttvv3TUUUelww47LLdfUVFRevXVV6t9jL5u/vz5qX79+qlVq1bpiy++qLS9/PscEWnw4MFpxIgRacSIEemII45Ie+21V+41VKdOnfSTn/wkLV26tMrzvP7667nnUtOmTdO+++6bjjrqqDRo0KDUuXPnlJeXl1q2bFltzp133jmXY4sttkhLliypctz999+f+z526dIlDRs2LB1wwAGpfv366YADDkh77bVXioj09NNPV9ivT58+Va4vN2bMmCqfO+XP1zp16qQ+ffqk4cOHp1133TVFRLrwwgurfU+aNGlS7rHbfvvt07Bhw9LBBx+cGjRokIYMGZLatm2bIqLCf29//vnnqWfPnikiUuPGjdOAAQPSkUcemdq1a5fq16+fzjvvvBQRqU+fPhXOVf7e+PX1X/dNz73VPS7fdOxyn332WTrwwANTRKSGDRumQw45JA0dOjR3vVtttVV65ZVXKu1X3eNYrrrv36OPPpoiIjVo0CB973vfS8cdd1w6/vjj0z/+8Y81ylv+mHz99b+mGT755JPc+3tV7zvl7yOHHXZYhfVr83pZuXJlGjhwYO56S0pK0rBhw1KHDh1SQUFBOumkk1b7Hlr+8+XXv/71N14rAGxKvlWlbfl//GyxxRYVlnr16qUjjzwypZTSvHnz0g477JDOOeecNG3atPTMM8+kPn36pAMPPDCtWrWqlq4EgM3Z6krblFKaNWtWOvnkk1PHjh1TgwYNUpMmTVLv3r3TzTffnD7//PNK479aEn7wwQfpxz/+cdp2221TgwYNUps2bdJpp52WFi1aVKOMM2bMSBdddFHaf//9U5s2bVJBQUFq0KBB2nbbbdPAgQPTH//4x7Ry5crVHuOee+5J++67byosLEwNGzZM3/nOd9IVV1xRqXSuqZkzZ6bRo0en3XffPW211VapXr16qaioKPXo0SOdfvrpadq0aZWuZW1K25RSWrhwYfrpT3+atttuu5Sfn59at26dfvCDH6R33nmn2nJ2TUrb8lxHH310atu2bcrPz0/t2rVLP/nJT9L8+fOrLd7KTZkyJQ0fPjxts802qX79+qlZs2apW7du6dxzz03/+c9/KoxdtGhR+vGPf5zatm2bK7yreu7961//SieeeGLaYYcdUkFBQWrUqFHq2LFjKikpSTfccEOlX4J/U3H27rvvpksuuSQdeOCBqW3btqmgoCBtueWWqWvXrun8889Ps2fPXu3jU5WjjjoqRUR6/PHHK237amlbvtSpUycVFham9u3bp+9973vp8ssvr/T4VKWsrCxdddVVqXfv3qlp06a5snj33XdP55xzTnr++eer3feqq67Knf+bngPPPvtsOvDAA1Pz5s1To0aN0ne+8510+eWXp+XLl1db7q1tabtq1ap02223pZ49e6bGjRunoqKitM8++6QJEyaklFZfNv7zn/9Mhx12WGrWrFkqKChInTt3Tr/61a/S8uXLU4MGDVKdOnXSp59+WmGfJUuWpAsuuCDttNNOqaCgILVo0SINGjQovfLKK9WWs1kqbVP6snz+9a9/nfbcc8/UpEmT1KBBg7TddtulU089Nb3//vtV7rO2pW1KKd16661p1113TY0aNcodZ01K2JTWvbQ9/vjjU0SkAw44oMr39o8//jh17NgxRUQaN25chW1r83r5/PPP0zXXXJM6d+6c8vPz01ZbbZW+//3vp+nTp6/2PXTFihWpefPmqbCwsNpfiADApiovpQ38McS1KC8vLx588MEYNGhQRHx5T8Cjjz463njjjUqf2Nu4ceMoLi6Oiy66KCZOnBgvv/xybtv7778fbdq0iSlTpsSee+65MS8BAGps/PjxMXLkyBgxYkSMHz++tuPABvPyyy/HHnvsEYcffvg63VOY9ePZZ5+NPn36RJcuXaq8nzasb/fff38cccQRceaZZ8a1115b23EAYL2q/MkDm7EePXrEypUr44MPPojvfve7VY755JNPKn1ScnnB+9X7dgEAULt23333OOqoo+JPf/pTvPbaa9G1a9fajrTZW7hwYSxdujQ6dOhQYf3rr78eJ5xwQkRUf99eWJ9WrVoVl156aTRr1iwuvPDC2o4DAOvdZvdBZEuXLo3p06fnPn14xowZMX369Jg1a1bsuOOOcfTRR8cxxxwTDzzwQMyYMSNeeumlGDt2bDz22GMRETFgwIB4+eWX4+c//3m88847MW3atBg5cmS0a9cuevToUYtXBgDA11111VXRqFGj3AfesWG98cYb0bFjx9hll11i4MCBceSRR8buu+8e3bp1i//93/+Ngw46KE499dTajsm3wN133x3/+te/4he/+EU0a9astuMAwHq32d0eYfLkyblPE/6q8j8R/fzzz+Oyyy6Lu+66K+bMmRPNmzePPffcMy699NLo0qVLRERMmDAhrrrqqvjf//3faNSoUfTu3TuuvPLK6NSp08a+HACoMbdHADaUuXPnxi9/+ct45plnYs6cObFkyZJo0qRJ7LLLLnHUUUfFCSecEPXqfav+mA8AYIPY7EpbAAAAAIBN2WZ3ewQAAAAAgE2Z0hYAAAAAIEM2ixtOrVq1KubOnRtNmjSJvLy82o4DAAAAAFBJSimWLFkSrVu3jjp1qp9Pu1mUtnPnzo02bdrUdgwAAAAAgG80e/bs2HbbbavdvlmUtk2aNImILy+2sLCwltMAAAAAAFRWVlYWbdq0yfWZ1dksStvyWyIUFhYqbQEAAACATPumW7z6IDIAAAAAgAxR2gIAAAAAZIjSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkSL2aDB47dmw88MAD8dZbb0XDhg1jr732iiuvvDJ22mmn1e533333xUUXXRQzZ86MHXbYIa688so45JBDcttTSjFmzJi49dZb4+OPP4699947br755thhhx3W7qq+Jdqf/1itnn/mFQNq9fwAAAAAsDmq0UzbZ555Jk4++eR44YUX4qmnnorPP/88Dj744Fi2bFm1+zz//PMxfPjwOP744+PVV1+NQYMGxaBBg+L111/PjbnqqqvihhtuiFtuuSVefPHF2GKLLaKkpCQ+++yztb8yAAAAAIBNUF5KKa3tzgsXLowWLVrEM888E/vuu2+VY4YOHRrLli2LRx99NLduzz33jO7du8ctt9wSKaVo3bp1nHXWWXH22WdHRERpaWm0bNkyxo8fH8OGDfvGHGVlZVFUVBSlpaVRWFi4tpezyTHTFgAAAAA2HWvaY67TPW1LS0sjIqJZs2bVjpkyZUr07du3wrqSkpKYMmVKRETMmDEj5s+fX2FMUVFR9OrVKzfm65YvXx5lZWUVFgAAAACAzcFal7arVq2KM844I/bee+/4zne+U+24+fPnR8uWLSusa9myZcyfPz+3vXxddWO+buzYsVFUVJRb2rRps7aXAQAAAACQKWtd2p588snx+uuvx4QJE9ZnnjUyevToKC0tzS2zZ8/e6BkAAAAAADaEemuz0ymnnBKPPvpoPPvss7HtttuudmxxcXEsWLCgwroFCxZEcXFxbnv5ulatWlUY07179yqPmZ+fH/n5+WsTHQAAAAAg02o00zalFKeccko8+OCD8be//S06dOjwjfv07t07Jk2aVGHdU089Fb17946IiA4dOkRxcXGFMWVlZfHiiy/mxgAAAAAAfFvUaKbtySefHHfffXc8/PDD0aRJk9w9Z4uKiqJhw4YREXHMMcfENttsE2PHjo2IiNNPPz369OkT11xzTQwYMCAmTJgQr7zySvz2t7+NiIi8vLw444wz4rLLLosddtghOnToEBdddFG0bt06Bg0atB4vFQAAAAAg+2pU2t58880REbHffvtVWH/HHXfEscceGxERs2bNijp1/juBd6+99oq77747Lrzwwrjgggtihx12iIceeqjCh5ede+65sWzZsjjxxBPj448/jn322ScmTpwYBQUFa3lZAAAAAACbpryUUqrtEOuqrKwsioqKorS0NAoLC2s7zkbT/vzHavX8M68YUKvnBwAAAIBNyZr2mDW6py0AAAAAABuW0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyBClLQAAAABAhihtAQAAAAAyRGkLAAAAAJAhSlsAAAAAgAxR2gIAAAAAZIjSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyBClLQAAAABAhihtAQAAAAAyRGkLAAAAAJAhNS5tn3322Rg4cGC0bt068vLy4qGHHlrt+GOPPTby8vIqLbvssktuzCWXXFJpe6dOnWp8MQAAAAAAm7oal7bLli2Lbt26xU033bRG46+//vqYN29ebpk9e3Y0a9YshgwZUmHcLrvsUmHcc889V9NoAAAAAACbvHo13aF///7Rv3//NR5fVFQURUVFua8feuihWLx4cYwcObJikHr1ori4uKZxAAAAAAA2Kxv9nra33XZb9O3bN9q1a1dh/TvvvBOtW7eOjh07xtFHHx2zZs2q9hjLly+PsrKyCgsAAAAAwOZgo5a2c+fOjf/3//5f/OhHP6qwvlevXjF+/PiYOHFi3HzzzTFjxoz47ne/G0uWLKnyOGPHjs3N4C0qKoo2bdpsjPgAAAAAABvcRi1t77zzzmjatGkMGjSowvr+/fvHkCFDomvXrlFSUhKPP/54fPzxx3HvvfdWeZzRo0dHaWlpbpk9e/ZGSA8AAAAAsOHV+J62ayulFLfffnv88Ic/jAYNGqx2bNOmTWPHHXeMd999t8rt+fn5kZ+fvyFiAgAAAADUqo020/aZZ56Jd999N44//vhvHLt06dJ47733olWrVhshGQAAAABAdtS4tF26dGlMnz49pk+fHhERM2bMiOnTp+c+OGz06NFxzDHHVNrvtttui169esV3vvOdStvOPvvseOaZZ2LmzJnx/PPPx2GHHRZ169aN4cOH1zQeAAAAAMAmrca3R3jllVdi//33z309atSoiIgYMWJEjB8/PubNm5crcMuVlpbG/fffH9dff32Vx3z//fdj+PDhsWjRoth6661jn332iRdeeCG23nrrmsYDAAAAANik5aWUUm2HWFdlZWVRVFQUpaWlUVhYWNtxNpr25z9Wq+efecWAWj0/AAAAAGxK1rTH3Gj3tAUAAAAA4JspbQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyBClLQAAAABAhihtAQAAAAAyRGkLAAAAAJAhSlsAAAAAgAxR2gIAAAAAZIjSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABlS49L22WefjYEDB0br1q0jLy8vHnroodWOnzx5cuTl5VVa5s+fX2HcTTfdFO3bt4+CgoLo1atXvPTSSzWNBgAAAACwyatxabts2bLo1q1b3HTTTTXa7+2334558+bllhYtWuS23XPPPTFq1KgYM2ZMTJs2Lbp16xYlJSXxwQcf1DQeAAAAAMAmrV5Nd+jfv3/079+/xidq0aJFNG3atMpt1157bZxwwgkxcuTIiIi45ZZb4rHHHovbb789zj///BqfCwAAAABgU7XR7mnbvXv3aNWqVRx00EHxj3/8I7d+xYoVMXXq1Ojbt+9/Q9WpE3379o0pU6ZUeazly5dHWVlZhQUAAAAAYHOwwUvbVq1axS233BL3339/3H///dGmTZvYb7/9Ytq0aRER8eGHH8bKlSujZcuWFfZr2bJlpfvelhs7dmwUFRXlljZt2mzoywAAAAAA2ChqfHuEmtppp51ip512yn291157xXvvvRfXXXdd/P73v1+rY44ePTpGjRqV+7qsrExxCwAAAABsFjZ4aVuVPfbYI5577rmIiGjevHnUrVs3FixYUGHMggULori4uMr98/PzIz8/f4PnBAAAAADY2DbaPW2/avr06dGqVauIiGjQoEH07NkzJk2alNu+atWqmDRpUvTu3bs24gEAAAAA1Joaz7RdunRpvPvuu7mvZ8yYEdOnT49mzZpF27ZtY/To0TFnzpy46667IiJi3Lhx0aFDh9hll13is88+i9/97nfxt7/9LZ588sncMUaNGhUjRoyI3XbbLfbYY48YN25cLFu2LEaOHLkeLhEAAAAAYNNR49L2lVdeif333z/3dfm9ZUeMGBHjx4+PefPmxaxZs3LbV6xYEWeddVbMmTMnGjVqFF27do2//vWvFY4xdOjQWLhwYVx88cUxf/786N69e0ycOLHSh5MBAAAAAGzu8lJKqbZDrKuysrIoKiqK0tLSKCwsrO04G0378x+r1fPPvGJArZ4fAAAAADYla9pj1so9bQEAAAAAqJrSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyBClLQAAAABAhihtAQAAAAAyRGkLAAAAAJAhSlsAAAAAgAxR2gIAAAAAZIjSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCE1Lm2fffbZGDhwYLRu3Try8vLioYceWu34Bx54IA466KDYeuuto7CwMHr37h1PPPFEhTGXXHJJ5OXlVVg6depU02gAAAAAAJu8Gpe2y5Yti27dusVNN920RuOfffbZOOigg+Lxxx+PqVOnxv777x8DBw6MV199tcK4XXbZJebNm5dbnnvuuZpGAwAAAADY5NWr6Q79+/eP/v37r/H4cePGVfj6l7/8ZTz88MPxyCOPRI8ePf4bpF69KC4urmkcAAAAAIDNyka/p+2qVatiyZIl0axZswrr33nnnWjdunV07Ngxjj766Jg1a1a1x1i+fHmUlZVVWAAAAAAANgcbvbS9+uqrY+nSpXHkkUfm1vXq1SvGjx8fEydOjJtvvjlmzJgR3/3ud2PJkiVVHmPs2LFRVFSUW9q0abOx4gMAAAAAbFAbtbS9++6749JLL4177703WrRokVvfv3//GDJkSHTt2jVKSkri8ccfj48//jjuvffeKo8zevToKC0tzS2zZ8/eWJcAAAAAALBB1fietmtrwoQJ8aMf/Sjuu+++6Nu372rHNm3aNHbcccd49913q9yen58f+fn5GyImAAAAAECt2igzbf/0pz/FyJEj409/+lMMGDDgG8cvXbo03nvvvWjVqtVGSAcAAAAAkB01nmm7dOnSCjNgZ8yYEdOnT49mzZpF27ZtY/To0TFnzpy46667IuLLWyKMGDEirr/++ujVq1fMnz8/IiIaNmwYRUVFERFx9tlnx8CBA6Ndu3Yxd+7cGDNmTNStWzeGDx++Pq4RAAAAAGCTUeOZtq+88kr06NEjevToERERo0aNih49esTFF18cERHz5s2LWbNm5cb/9re/jS+++CJOPvnkaNWqVW45/fTTc2Pef//9GD58eOy0005x5JFHxlZbbRUvvPBCbL311ut6fQAAAAAAm5S8lFKq7RDrqqysLIqKiqK0tDQKCwtrO85G0/78x2r1/DOv+OZbXQAAAAAAX1rTHnOj3NMWAAAAAIA1o7QFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyBClLQAAAABAhihtAQAAAAAyRGkLAAAAAJAhSlsAAAAAgAxR2gIAAAAAZIjSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkSI1L22effTYGDhwYrVu3jry8vHjooYe+cZ/JkyfHrrvuGvn5+bH99tvH+PHjK4256aabon379lFQUBC9evWKl156qabRAAAAAAA2eTUubZctWxbdunWLm266aY3Gz5gxIwYMGBD7779/TJ8+Pc4444z40Y9+FE888URuzD333BOjRo2KMWPGxLRp06Jbt25RUlISH3zwQU3jAQAAAABs0vJSSmmtd87LiwcffDAGDRpU7ZjzzjsvHnvssXj99ddz64YNGxYff/xxTJw4MSIievXqFbvvvnvceOONERGxatWqaNOmTZx66qlx/vnnf2OOsrKyKCoqitLS0igsLFzby9nktD//sVo9/8wrBtTq+QEAAABgU7KmPeYGv6ftlClTom/fvhXWlZSUxJQpUyIiYsWKFTF16tQKY+rUqRN9+/bNjQEAAAAA+Laot6FPMH/+/GjZsmWFdS1btoyysrL49NNPY/HixbFy5coqx7z11ltVHnP58uWxfPny3NdlZWXrPzgAAAAAQC3Y4DNtN4SxY8dGUVFRbmnTpk1tRwIAAAAAWC82eGlbXFwcCxYsqLBuwYIFUVhYGA0bNozmzZtH3bp1qxxTXFxc5TFHjx4dpaWluWX27NkbLD8AAAAAwMa0wUvb3r17x6RJkyqse+qpp6J3794REdGgQYPo2bNnhTGrVq2KSZMm5cZ8XX5+fhQWFlZYAAAAAAA2BzUubZcuXRrTp0+P6dOnR0TEjBkzYvr06TFr1qyI+HIW7DHHHJMb/5Of/CT+7//+L84999x466234te//nXce++9ceaZZ+bGjBo1Km699da4884749///necdNJJsWzZshg5cuQ6Xh4AAAAAwKalxh9E9sorr8T++++f+3rUqFERETFixIgYP358zJs3L1fgRkR06NAhHnvssTjzzDPj+uuvj2233TZ+97vfRUlJSW7M0KFDY+HChXHxxRfH/Pnzo3v37jFx4sRKH04GAAAAALC5y0sppdoOsa7KysqiqKgoSktLv1W3Smh//mO1ev6ZVwyo1fMDAAAAwKZkTXvMDX5PWwAAAAAA1pzSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyBClLQAAAABAhihtAQAAAAAyRGkLAAAAAJAhSlsAAAAAgAxR2gIAAAAAZIjSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFrVdredNNN0b59+ygoKIhevXrFSy+9VO3Y/fbbL/Ly8iotAwYMyI059thjK23v16/f2kQDAAAAANik1avpDvfcc0+MGjUqbrnllujVq1eMGzcuSkpK4u23344WLVpUGv/AAw/EihUrcl8vWrQounXrFkOGDKkwrl+/fnHHHXfkvs7Pz69pNAAAAACATV6NZ9pee+21ccIJJ8TIkSOjc+fOccstt0SjRo3i9ttvr3J8s2bNori4OLc89dRT0ahRo0qlbX5+foVxW2655dpdEQAAAADAJqxGpe2KFSti6tSp0bdv3/8eoE6d6Nu3b0yZMmWNjnHbbbfFsGHDYosttqiwfvLkydGiRYvYaaed4qSTTopFixbVJBoAAAAAwGahRrdH+PDDD2PlypXRsmXLCutbtmwZb7311jfu/9JLL8Xrr78et912W4X1/fr1i8MPPzw6dOgQ7733XlxwwQXRv3//mDJlStStW7fScZYvXx7Lly/PfV1WVlaTywAAAAAAyKwa39N2Xdx2223RpUuX2GOPPSqsHzZsWO7/d+nSJbp27RrbbbddTJ48OQ488MBKxxk7dmxceumlGzwvAAAAAMDGVqPbIzRv3jzq1q0bCxYsqLB+wYIFUVxcvNp9ly1bFhMmTIjjjz/+G8/TsWPHaN68ebz77rtVbh89enSUlpbmltmzZ6/5RQAAAAAAZFiNStsGDRpEz549Y9KkSbl1q1atikmTJkXv3r1Xu+99990Xy5cvjx/84AffeJ73338/Fi1aFK1atapye35+fhQWFlZYAAAAAAA2BzUqbSMiRo0aFbfeemvceeed8e9//ztOOumkWLZsWYwcOTIiIo455pgYPXp0pf1uu+22GDRoUGy11VYV1i9dujTOOeeceOGFF2LmzJkxadKk+P73vx/bb799lJSUrOVlAQAAAABsmmp8T9uhQ4fGwoUL4+KLL4758+dH9+7dY+LEibkPJ5s1a1bUqVOxC3777bfjueeeiyeffLLS8erWrRuvvfZa3HnnnfHxxx9H69at4+CDD45f/OIXkZ+fv5aXBQAAAACwacpLKaXaDrGuysrKoqioKEpLS79Vt0pof/5jtXr+mVcMqNXzAwAAAMCmZE17zBrfHgEAAAAAgA1HaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABlSr7YDsPlqf/5jtR0hZl4xoLYjAAAAAECNmGkLAAAAAJAhSlsAAAAAgAxR2gIAAAAAZIjSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMkRpCwAAAACQIUpbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyJB6tR0AalP78x+r1fPPvGJArZ4fAAAAgOwx0xYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECG+CAyyDgflgYAAADw7WKmLQAAAABAhihtAQAAAAAyRGkLAAAAAJAhSlsAAAAAgAxZq9L2pptuivbt20dBQUH06tUrXnrppWrHjh8/PvLy8iosBQUFFcaklOLiiy+OVq1aRcOGDaNv377xzjvvrE00AAAAAIBNWr2a7nDPPffEqFGj4pZbbolevXrFuHHjoqSkJN5+++1o0aJFlfsUFhbG22+/nfs6Ly+vwvarrroqbrjhhrjzzjujQ4cOcdFFF0VJSUm8+eablQpeIFvan/9YbUeImVcMqO0IAAAAAOtNjWfaXnvttXHCCSfEyJEjo3PnznHLLbdEo0aN4vbbb692n7y8vCguLs4tLVu2zG1LKcW4cePiwgsvjO9///vRtWvXuOuuu2Lu3Lnx0EMPrdVFAQAAAABsqmpU2q5YsSKmTp0affv2/e8B6tSJvn37xpQpU6rdb+nSpdGuXbto06ZNfP/734833ngjt23GjBkxf/78CscsKiqKXr16rfaYAAAAAACboxqVth9++GGsXLmywkzZiIiWLVvG/Pnzq9xnp512ittvvz0efvjh+MMf/hCrVq2KvfbaK95///2IiNx+NTnm8uXLo6ysrMICAAAAALA5WKsPIquJ3r17xzHHHBPdu3ePPn36xAMPPBBbb711/OY3v1nrY44dOzaKiopyS5s2bdZjYgAAAACA2lOj0rZ58+ZRt27dWLBgQYX1CxYsiOLi4jU6Rv369aNHjx7x7rvvRkTk9qvJMUePHh2lpaW5Zfbs2TW5DAAAAACAzKpRadugQYPo2bNnTJo0Kbdu1apVMWnSpOjdu/caHWPlypXxr3/9K1q1ahURER06dIji4uIKxywrK4sXX3yx2mPm5+dHYWFhhQUAAAAAYHNQr6Y7jBo1KkaMGBG77bZb7LHHHjFu3LhYtmxZjBw5MiIijjnmmNhmm21i7NixERHx85//PPbcc8/Yfvvt4+OPP45f/epX8Z///Cd+9KMfRUREXl5enHHGGXHZZZfFDjvsEB06dIiLLrooWrduHYMGDVp/VwoAAAAAsAmocWk7dOjQWLhwYVx88cUxf/786N69e0ycODH3QWKzZs2KOnX+O4F38eLFccIJJ8T8+fNjyy23jJ49e8bzzz8fnTt3zo0599xzY9myZXHiiSfGxx9/HPvss09MnDgxCgoK1sMlAgAAAABsOmpc2kZEnHLKKXHKKadUuW3y5MkVvr7uuuviuuuuW+3x8vLy4uc//3n8/Oc/X5s4AAAAAACbjRrd0xYAAAAAgA1LaQsAAAAAkCFKWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyBClLQAAAABAhihtAQAAAAAyRGkLAAAAAJAhSlsAAAAAgAxR2gIAAAAAZIjSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMqRebQcA2NDan/9YrZ5/5hUDavX8AAAAwKbFTFsAAAAAgAxR2gIAAAAAZIjSFgAAAAAgQ5S2AAAAAAAZorQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMqRebQcA+LZrf/5jtR0hZl4xoLYjAAAAAP8/pS0A36i2i2WlMgAAAN8mbo8AAAAAAJAhZtoCsMmr7ZnAEd88G7i2M5qtDAAAsOkw0xYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADKkXm0HAABqX/vzH6vtCDHzigG1HQEAACATzLQFAAAAAMgQpS0AAAAAQIa4PQIAsElwCwcAAODbwkxbAAAAAIAMUdoCAAAAAGTIWt0e4aabbopf/epXMX/+/OjWrVv8z//8T+yxxx5Vjr311lvjrrvuitdffz0iInr27Bm//OUvK4w/9thj484776ywX0lJSUycOHFt4gEA1IravoWD2zcAAMDmocYzbe+5554YNWpUjBkzJqZNmxbdunWLkpKS+OCDD6ocP3ny5Bg+fHg8/fTTMWXKlGjTpk0cfPDBMWfOnArj+vXrF/Pmzcstf/rTn9buigAAAAAANmE1Lm2vvfbaOOGEE2LkyJHRuXPnuOWWW6JRo0Zx++23Vzn+j3/8Y/z0pz+N7t27R6dOneJ3v/tdrFq1KiZNmlRhXH5+fhQXF+eWLbfccu2uCAAAAABgE1aj0nbFihUxderU6Nu3738PUKdO9O3bN6ZMmbJGx/jkk0/i888/j2bNmlVYP3ny5GjRokXstNNOcdJJJ8WiRYuqPcby5cujrKyswgIAAAAAsDmo0T1tP/zww1i5cmW0bNmywvqWLVvGW2+9tUbHOO+886J169YVit9+/frF4YcfHh06dIj33nsvLrjggujfv39MmTIl6tatW+kYY8eOjUsvvbQm0QEAvvVq+567Ee67CwAAa2KtPohsbV1xxRUxYcKEmDx5chQUFOTWDxs2LPf/u3TpEl27do3tttsuJk+eHAceeGCl44wePTpGjRqV+7qsrCzatGmzYcMDAAAAAGwENbo9QvPmzaNu3bqxYMGCCusXLFgQxcXFq9336quvjiuuuCKefPLJ6Nq162rHduzYMZo3bx7vvvtuldvz8/OjsLCwwgIAAAAAsDmoUWnboEGD6NmzZ4UPESv/ULHevXtXu99VV10Vv/jFL2LixImx2267feN53n///Vi0aFG0atWqJvEAAAAAADZ5Nb49wqhRo2LEiBGx2267xR577BHjxo2LZcuWxciRIyMi4phjjoltttkmxo4dGxERV155ZVx88cVx9913R/v27WP+/PkREdG4ceNo3LhxLF26NC699NIYPHhwFBcXx3vvvRfnnntubL/99lFSUrIeLxUAgKyr7fvuuucuAABZUOPSdujQobFw4cK4+OKLY/78+dG9e/eYOHFi7sPJZs2aFXXq/HcC78033xwrVqyII444osJxxowZE5dccknUrVs3Xnvttbjzzjvj448/jtatW8fBBx8cv/jFLyI/P38dLw8AANaf2i6VIxTLAADfBmv1QWSnnHJKnHLKKVVumzx5coWvZ86cudpjNWzYMJ544om1iQEAAAAAsNlZq9IWAADIptqeDWwmMADAuqvRB5EBAAAAALBhKW0BAAAAADJEaQsAAAAAkCHuaQsAAGw0tX3P3Qj33QUAss9MWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyJB6tR0AAAAgS9qf/1itnn/mFQNq9fwAQO0z0xYAAAAAIEOUtgAAAAAAGeL2CAAAAJsYt3AAgM2bmbYAAAAAABlipi0AAADrVW3PBI4wGxiATZuZtgAAAAAAGWKmLQAAAN86tT0b2ExgAFZHaQsAAAAZU9ulcoRiGaA2uT0CAAAAAECGmGkLAAAA1FhtzwY2ExjYnJlpCwAAAACQIWbaAgAAAJud2p4JHGE2MLD2zLQFAAAAAMgQpS0AAAAAQIa4PQIAAABALajtWzi4fQNkl9IWAAAAgEpqu1SOUCzz7aW0BQAAAGCTVNvFslKZDUVpCwAAAAAbiGKZteGDyAAAAAAAMsRMWwAAAAD4lqrtmcARZgNXxUxbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGaK0BQAAAADIEKUtAAAAAECGKG0BAAAAADJEaQsAAAAAkCFrVdredNNN0b59+ygoKIhevXrFSy+9tNrx9913X3Tq1CkKCgqiS5cu8fjjj1fYnlKKiy++OFq1ahUNGzaMvn37xjvvvLM20QAAAAAANmk1Lm3vueeeGDVqVIwZMyamTZsW3bp1i5KSkvjggw+qHP/888/H8OHD4/jjj49XX301Bg0aFIMGDYrXX389N+aqq66KG264IW655ZZ48cUXY4sttoiSkpL47LPP1v7KAAAAAAA2QTUuba+99to44YQTYuTIkdG5c+e45ZZbolGjRnH77bdXOf7666+Pfv36xTnnnBM777xz/OIXv4hdd901brzxxoj4cpbtuHHj4sILL4zvf//70bVr17jrrrti7ty58dBDD63TxQEAAAAAbGrq1WTwihUrYurUqTF69Ojcujp16kTfvn1jypQpVe4zZcqUGDVqVIV1JSUluUJ2xowZMX/+/Ojbt29ue1FRUfTq1SumTJkSw4YNq3TM5cuXx/Lly3Nfl5aWRkREWVlZTS5nk7dq+Se1ev5verxrO19E9jOuyXM26xlrO19E9jNmPV9E9jNmPV9E9jNmPV+EjOtD1vNFZD9j1vNFZD9j1vNFZD+j/0ZcP7KeMev5IrKfMev5IrKfMev5IrKf0Xv2+vFt6vTKrzWltPqBqQbmzJmTIiI9//zzFdafc845aY899qhyn/r166e77767wrqbbroptWjRIqWU0j/+8Y8UEWnu3LkVxgwZMiQdeeSRVR5zzJgxKSIsFovFYrFYLBaLxWKxWCwWi2WTW2bPnr3aHrZGM22zYvTo0RVm765atSo++uij2GqrrSIvL68Wk206ysrKok2bNjF79uwoLCys7ThVynrGrOeLyH7GrOeLyH7GrOeLkHF9yHq+iOxnzHq+iOxnzHq+CBnXh6zni8h+xqzni8h+xqzni8h+xqzni5Bxfch6vojsZ8x6vojsZ8x6vixKKcWSJUuidevWqx1Xo9K2efPmUbdu3ViwYEGF9QsWLIji4uIq9ykuLl7t+PL/XbBgQbRq1arCmO7du1d5zPz8/MjPz6+wrmnTpjW5FP5/hYWFmX9RZT1j1vNFZD9j1vNFZD9j1vNFyLg+ZD1fRPYzZj1fRPYzZj1fhIzrQ9bzRWQ/Y9bzRWQ/Y9bzRWQ/Y9bzRci4PmQ9X0T2M2Y9X0T2M2Y9X9YUFRV945gafRBZgwYNomfPnjFp0qTculWrVsWkSZOid+/eVe7Tu3fvCuMjIp566qnc+A4dOkRxcXGFMWVlZfHiiy9We0wAAAAAgM1VjW+PMGrUqBgxYkTstttusccee8S4ceNi2bJlMXLkyIiIOOaYY2KbbbaJsWPHRkTE6aefHn369IlrrrkmBgwYEBMmTIhXXnklfvvb30ZERF5eXpxxxhlx2WWXxQ477BAdOnSIiy66KFq3bh2DBg1af1cKAAAAALAJqHFpO3To0Fi4cGFcfPHFMX/+/OjevXtMnDgxWrZsGRERs2bNijp1/juBd6+99oq77747Lrzwwrjgggtihx12iIceeii+853v5Mace+65sWzZsjjxxBPj448/jn322ScmTpwYBQUF6+ESqUp+fn6MGTOm0m0msiTrGbOeLyL7GbOeLyL7GbOeL0LG9SHr+SKynzHr+SKynzHr+SJkXB+yni8i+xmzni8i+xmzni8i+xmzni9CxvUh6/kisp8x6/kisp8x6/k2ZXkppVTbIQAAAAAA+FKN7mkLAAAAAMCGpbQFAAAAAMgQpS0AAAAAQIYobQEAAAAAMqRebQeAGTNmxNp+Hl7Hjh3Xc5rKsp4vIvsZs54vIvsZs54vIvsZs54vQsb1Iev5IrKfMev5IrKfMev5IrKfMev5ImRcH7KeLyL7GbOeLyL7GbOeLyL7GbOeL0LG9SHr+TZHeWltH3FYTwoKCmLXXXet8Yt/6tSpsWLFig2U6r+yni8i+xmzni8i+xmzni8i+xmzni9CxvUh6/kisp8x6/kisp8x6/kisp8x6/kiZFwfsp4vIvsZs54vIvsZs54vIvsZs54vQsb1Iev5NkdKW2pdkyZNYsmSJTXeb8stt4zFixdvgEQVZT1fRPYzZj1fRPYzZj1fRPYzZj1fhIzrQ9bzRWQ/Y9bzRWQ/Y9bzRWQ/Y9bzRci4PmQ9X0T2M2Y9X0T2M2Y9X0T2M2Y9X4SM60PW822O3NOWWpeXl7dR99tY59lY+dblXB7DdT+Xx3Ddz+UxXPdzybju5/EYrvt5PIbrfh6P4bqfx2O4fs7l+7zu5/IYrvu5PIbrfi6P4bqfS8Z1P8/GfAw3N0pbAAAAAIAMUdoCAAAAAGSI0hYAAAAAIEOUtgAAAAAAGVKvtgPA8uXLY999963RPimlWLp06QZKVFHW80VkP2PW80VkP2PW80VkP2PW80XIuD5kPV9E9jNmPV9E9jNmPV9E9jNmPV+EjOtD1vNFZD9j1vNFZD9j1vNFZD9j1vNFyLg+ZD3f5khpS6179dVXI6VU2zGqlfV8EdnPmPV8EdnPmPV8EdnPmPV8ETKuD1nPF5H9jFnPF5H9jFnPF5H9jFnPFyHj+pD1fBHZz5j1fBHZz5j1fBHZz5j1fBEyrg9Zz7c5yksecQAAAACAzHBPWwAAAACADFHaAgAAAABkiNIWAAAAACBDlLYAAAAAABmitAUAAAAAyBClLQAAAABAhihtAQAAAAAyRGkLAAAAAJAh/x+8IkmqFTrjCQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1400x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example using your stats\n",
        "top_chars = stats['top_chars'][:30]\n",
        "chars, counts = zip(*top_chars)\n",
        "\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.bar(range(len(chars)), counts)\n",
        "plt.xticks(range(len(chars)), chars, rotation=90, fontsize=12)\n",
        "plt.title(\"Top 30 Characters (Devanagari Font Fixed)\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Jyj6Kc9IcrI"
      },
      "outputs": [],
      "source": [
        "# Run once in Colab\n",
        "!pip install -q tokenizers datasets tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDmnlIw9KZ-Y",
        "outputId": "9e22daf6-bebc-47f7-fad9-1327e5ff05f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected text key: text\n"
          ]
        }
      ],
      "source": [
        "def detect_text_key(example):\n",
        "    if isinstance(example, str):\n",
        "        return None\n",
        "    for k, v in example.items():\n",
        "        if isinstance(v, str):\n",
        "            return k\n",
        "    return None\n",
        "\n",
        "sample = train[0]\n",
        "text_key = detect_text_key(sample)\n",
        "print(\"Detected text key:\", text_key)\n",
        "\n",
        "def training_iterator(split, text_key=text_key):\n",
        "    # yields str lines for tokenizer training\n",
        "    for ex in split:\n",
        "        if text_key is None:\n",
        "            yield ex if isinstance(ex, str) else str(ex)\n",
        "        else:\n",
        "            yield ex.get(text_key, \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX0vqnYLr9VG"
      },
      "source": [
        "**Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4pn04gJIccg"
      },
      "outputs": [],
      "source": [
        "##\n",
        "\n",
        "\n",
        "\n",
        "from collections import Counter, defaultdict\n",
        "import re\n",
        "\n",
        "# Build initial vocab from list of words (with end-of-word marker)\n",
        "def get_vocab(words):\n",
        "    \"\"\"\n",
        "    words: iterable of strings (words / tokens)\n",
        "    returns: dict mapping tuple(chars + </w>) -> frequency\n",
        "    \"\"\"\n",
        "    vocab = Counter()\n",
        "    for w in words:\n",
        "        # split into characters; you can also split on unicode codepoints explicitly\n",
        "        chars = list(w)\n",
        "        token = tuple(chars + ['</w>'])\n",
        "        vocab[token] += 1\n",
        "    return vocab\n",
        "\n",
        "def get_stats(vocab):\n",
        "    \"\"\"Return counts of adjacent symbol pairs (pair -> frequency).\"\"\"\n",
        "    pairs = defaultdict(int)\n",
        "    for token, freq in vocab.items():\n",
        "        symbols = token\n",
        "        for i in range(len(symbols)-1):\n",
        "            pair = (symbols[i], symbols[i+1])\n",
        "            pairs[pair] += freq\n",
        "    return pairs\n",
        "\n",
        "def merge_vocab(pair, vocab):\n",
        "    \"\"\"Merge all occurrences of the most frequent pair in the vocab.\"\"\"\n",
        "    merged_vocab = {}\n",
        "    bigram = re.escape(' '.join(pair))\n",
        "    # Efficient approach: iterate tokens and replace adjacent pair occurrences\n",
        "    a, b = pair\n",
        "    for token, freq in vocab.items():\n",
        "        token_list = list(token)\n",
        "        i = 0\n",
        "        new_token = []\n",
        "        while i < len(token_list):\n",
        "            if i < len(token_list)-1 and token_list[i] == a and token_list[i+1] == b:\n",
        "                # merge\n",
        "                new_token.append(a + b)   # merged symbol\n",
        "                i += 2\n",
        "            else:\n",
        "                new_token.append(token_list[i])\n",
        "                i += 1\n",
        "        merged_vocab[tuple(new_token)] = freq\n",
        "    return merged_vocab\n",
        "\n",
        "def bpe_learn(words, num_merges=100):\n",
        "    \"\"\"\n",
        "    Learn BPE merges from the list of words.\n",
        "    Returns final vocab (mapping of symbol sequences to frequencies) and merges list.\n",
        "    \"\"\"\n",
        "    vocab = get_vocab(words)\n",
        "    merges = []\n",
        "    for i in range(num_merges):\n",
        "        pairs = get_stats(vocab)\n",
        "        if not pairs:\n",
        "            break\n",
        "        best = max(pairs, key=pairs.get)\n",
        "        merges.append(best)\n",
        "        vocab = merge_vocab(best, vocab)\n",
        "        if (i+1) % 10 == 0:\n",
        "            print(f\"Completed {i+1} merges...\")\n",
        "    return vocab, merges\n",
        "\n",
        "def bpe_tokenize_word(word, merges):\n",
        "    \"\"\"\n",
        "    Tokenize a single word (string) using learned merges list (in order).\n",
        "    \"\"\"\n",
        "    symbols = list(word) + ['</w>']\n",
        "    for a, b in merges:\n",
        "        i = 0\n",
        "        merged_symbol = a + b\n",
        "        while i < len(symbols) - 1:\n",
        "            if symbols[i] == a and symbols[i+1] == b:\n",
        "                symbols = symbols[:i] + [merged_symbol] + symbols[i+2:]\n",
        "                # after merge we step back one position to allow overlapping merges\n",
        "                i = max(i-1, 0)\n",
        "            else:\n",
        "                i += 1\n",
        "    # remove end marker for presentation if needed\n",
        "    if symbols and symbols[-1] == '</w>':\n",
        "        symbols = symbols[:-1]\n",
        "    return symbols\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZTmU57wLHrq",
        "outputId": "9f413b30-0725-423b-871c-445fea9d4b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collected words: 6934909\n",
            "Completed 10 merges...\n",
            "Completed 20 merges...\n",
            "Completed 30 merges...\n",
            "Completed 40 merges...\n",
            "Completed 50 merges...\n",
            "Completed 60 merges...\n",
            "Completed 70 merges...\n",
            "Completed 80 merges...\n",
            "Completed 90 merges...\n",
            "Completed 100 merges...\n",
            "Completed 110 merges...\n",
            "Completed 120 merges...\n",
            "Completed 130 merges...\n",
            "Completed 140 merges...\n",
            "Completed 150 merges...\n",
            "Completed 160 merges...\n",
            "Completed 170 merges...\n",
            "Completed 180 merges...\n",
            "Completed 190 merges...\n",
            "Completed 200 merges...\n",
            "Number of merges learned: 200\n",
            "Top merges: [('े', '</w>'), ('ा', '</w>'), ('ी', '</w>'), ('र', '</w>'), ('ं', '</w>'), ('क', 'े</w>'), ('ह', 'ै'), ('।', '</w>'), ('न', '</w>'), ('्', 'र'), ('े', 'ं</w>'), ('ो', '</w>'), ('न', 'े</w>'), ('म', 'ें</w>'), ('र', '्'), ('क', '</w>'), ('क', 'ी</w>'), ('त', '</w>'), ('स', 'े</w>'), ('क', 'ि'), ('स', '</w>'), ('ल', '</w>'), ('्', 'य'), ('ो', 'ं</w>'), ('स', '्'), ('ा', 'र'), ('क', 'ो</w>'), ('य', 'ा</w>'), ('म', '</w>'), ('क', 'ा</w>')]\n",
            "Sample word: समाचार\n",
            "Tokenized: ['स', 'मा', 'चा', 'र</w>']\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "# Build a word list from a small slice of your dataset (for speed)\n",
        "def get_word_list_from_dataset(split, text_key=None, max_lines=200000):\n",
        "    words = []\n",
        "    for i, ex in enumerate(split):\n",
        "        if i >= max_lines:\n",
        "            break\n",
        "        text = ex if text_key is None else ex.get(text_key, \"\")\n",
        "        # simple whitespace split; for Hindi you might split using regex to keep Devanagari tokens\n",
        "        tokens = re.findall(r\"[\\u0900-\\u097F]+|[A-Za-z0-9]+\", text)\n",
        "        for t in tokens:\n",
        "            words.append(t)\n",
        "    return words\n",
        "\n",
        "# Build words\n",
        "words = get_word_list_from_dataset(train, text_key, max_lines=20000)\n",
        "print(\"Collected words:\", len(words))\n",
        "\n",
        "# Learn merges (small number to keep it fast)\n",
        "vocab_after, merges = bpe_learn(words, num_merges=200)\n",
        "\n",
        "print(\"Number of merges learned:\", len(merges))\n",
        "print(\"Top merges:\", merges[:30])\n",
        "\n",
        "# Tokenize a sample word\n",
        "sample_word = words[0]\n",
        "print(\"Sample word:\", sample_word)\n",
        "print(\"Tokenized:\", bpe_tokenize_word(sample_word, merges[:1000]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6fKmnTvRwIO",
        "outputId": "6737111f-b73a-4b72-934b-a08f58247d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: समाचार\n",
            "BPE Tokens: ['स', 'मा', 'चा', 'र</w>']\n"
          ]
        }
      ],
      "source": [
        "# Test your pure-Python BPE tokenizer on a single word\n",
        "test_word = \"समाचार\"\n",
        "\n",
        "tokens = bpe_tokenize_word(test_word, merges)\n",
        "print(\"Word:\", test_word)\n",
        "print(\"BPE Tokens:\", tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqhr_4_ASXzh"
      },
      "outputs": [],
      "source": [
        "def bpe_tokenize_sentence(sentence, merges):\n",
        "    # Split into words using your Hindi regex\n",
        "    words = re.findall(r\"[\\u0900-\\u097F]+|[A-Za-z0-9]+\", sentence)\n",
        "\n",
        "    output_tokens = []\n",
        "    for w in words:\n",
        "        sub_tokens = bpe_tokenize_word(w, merges)\n",
        "        output_tokens.extend(sub_tokens)\n",
        "    return output_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEyfqnjSSbMs",
        "outputId": "385c625c-51c7-4db4-df3a-64df2bdb4b3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: यह एक नया वाक्य है।\n",
            "BPE Tokens: ['यह</w>', 'एक</w>', 'न', 'या</w>', 'वा', 'क', '्य</w>', 'है।</w>']\n"
          ]
        }
      ],
      "source": [
        "test_sentence = \"यह एक नया वाक्य है।\"\n",
        "\n",
        "bpe_tokens = bpe_tokenize_sentence(test_sentence, merges)\n",
        "\n",
        "print(\"Sentence:\", test_sentence)\n",
        "print(\"BPE Tokens:\", bpe_tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8YrcYvsSv4S"
      },
      "source": [
        "#GPT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc8e0pGtVBVJ",
        "outputId": "adf85897-359f-4f1c-fc25-2f24c455c8e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "token2id size: 361\n"
          ]
        }
      ],
      "source": [
        "# Ensure vocab_after exists from your BPE training:\n",
        "# vocab_after, merges = bpe_learn(words, num_merges=200)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# Extract all atomic symbols from vocab_after\n",
        "symbols = Counter()\n",
        "for token_tuple, freq in vocab_after.items():\n",
        "    for s in token_tuple:\n",
        "        symbols[s] += freq\n",
        "\n",
        "# Sort by frequency\n",
        "sorted_symbols = [sym for sym, _ in symbols.most_common()]\n",
        "\n",
        "# Build token → ID mapping\n",
        "token2id = {tok: idx for idx, tok in enumerate(sorted_symbols)}\n",
        "id2token = {idx: tok for tok, idx in token2id.items()}\n",
        "\n",
        "print(\"token2id size:\", len(token2id))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w59U32PzSuyj",
        "outputId": "63f2b2ab-3e5e-44c1-bc65-ff10ce24eee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your tokenizer vocab size: 361\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "# Replace GPT vocab with YOUR tokenizer vocab\n",
        "VOCAB_SIZE = len(token2id)\n",
        "\n",
        "GPT_CONFIG = {\n",
        "    \"vocab_size\": VOCAB_SIZE,\n",
        "    \"context_length\": 512,\n",
        "    \"emb_dim\": 512,\n",
        "    \"n_heads\": 4,\n",
        "    \"n_layers\": 4,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "print(\"Your tokenizer vocab size:\", GPT_CONFIG[\"vocab_size\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-KiqaFmamS-",
        "outputId": "c083cb90-df14-4076-c731-457bcd7600d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using tokenizer vocab size from token2id: 361\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# pick a vocab size: prefer token2id created from your BPE, otherwise fall back to GPT_CONFIG_124M\n",
        "try:\n",
        "    VOCAB_SIZE = len(token2id)\n",
        "    print(\"Using tokenizer vocab size from token2id:\", VOCAB_SIZE)\n",
        "except NameError:\n",
        "    VOCAB_SIZE = GPT_CONFIG[\"vocab_size\"]\n",
        "    print(\"token2id not found — using GPT_CONFIG_124M vocab size:\", VOCAB_SIZE)\n",
        "\n",
        "# Continue normally\n",
        "EMB_DIM = GPT_CONFIG[\"emb_dim\"]\n",
        "CTX_LEN = GPT_CONFIG[\"context_length\"]\n",
        "N_HEADS = GPT_CONFIG[\"n_heads\"]\n",
        "N_LAYERS = GPT_CONFIG[\"n_layers\"]\n",
        "DROP_RATE = GPT_CONFIG[\"drop_rate\"]\n",
        "QKV_BIAS = GPT_CONFIG[\"qkv_bias\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQD3f0oJbNgW",
        "outputId": "d3719b1d-038e-4d61-8e3b-84730ccdbc38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TokenPosEmbedding output shape: torch.Size([2, 10, 512])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class TokenPosEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, context_length):\n",
        "        super().__init__()\n",
        "        self.token_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # Learned positional embeddings\n",
        "        self.pos_emb = nn.Embedding(context_length, emb_dim)\n",
        "        self.emb_dropout = nn.Dropout(DROP_RATE)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"\n",
        "        input_ids: (B, T)\n",
        "        returns: (B, T, C)\n",
        "        \"\"\"\n",
        "        B, T = input_ids.shape\n",
        "        assert T <= self.pos_emb.num_embeddings, \"Sequence length exceeds context length\"\n",
        "        tok = self.token_emb(input_ids)                     # (B, T, C)\n",
        "        positions = torch.arange(0, T, device=input_ids.device).unsqueeze(0)  # (1, T)\n",
        "        pos = self.pos_emb(positions)                       # (1, T, C)\n",
        "        x = tok + pos\n",
        "        return self.emb_dropout(x)\n",
        "\n",
        "# Quick test\n",
        "embedding = TokenPosEmbedding(VOCAB_SIZE, EMB_DIM, CTX_LEN)\n",
        "input_ids = torch.randint(0, VOCAB_SIZE, (2, 10))\n",
        "out = embedding(input_ids)\n",
        "print(\"TokenPosEmbedding output shape:\", out.shape)   # expect (2, 10, EMB_DIM)\n",
        "assert out.shape == (2, 10, EMB_DIM)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBXnRZ_obRkw"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, emb_dim, n_heads, drop_rate=0.1, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert emb_dim % n_heads == 0\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = emb_dim // n_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(emb_dim, emb_dim * 3, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.attn_drop = nn.Dropout(drop_rate)\n",
        "        self.proj_drop = nn.Dropout(drop_rate)\n",
        "\n",
        "        # Causal mask will be created on-the-fly if needed\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        # x: (B, T, C)\n",
        "        B, T, C = x.size()\n",
        "        qkv = self.qkv(x)                          # (B, T, 3C)\n",
        "        qkv = qkv.view(B, T, 3, self.n_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]          # each (B, heads, T, head_dim)\n",
        "\n",
        "        # compute attention\n",
        "        att = torch.matmul(q, k.transpose(-2, -1)) * self.scale   # (B, heads, T, T)\n",
        "\n",
        "        # causal mask: allow only j <= i (triangular)\n",
        "        causal_mask = torch.tril(torch.ones((T, T), device=x.device)).unsqueeze(0).unsqueeze(0)  # (1,1,T,T)\n",
        "        att = att.masked_fill(causal_mask == 0, float('-inf'))\n",
        "\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.attn_drop(att)\n",
        "        y = torch.matmul(att, v)                   # (B, heads, T, head_dim)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        y = self.proj_drop(self.out_proj(y))\n",
        "        return y\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, emb_dim, ff_mult=4, drop_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(emb_dim, emb_dim * ff_mult),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(emb_dim * ff_mult, emb_dim),\n",
        "            nn.Dropout(drop_rate)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr8jlvxSbUbV",
        "outputId": "cb344b64-8887-4cae-a18e-99e38fa7c266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model created. Parameter count: 13051392\n"
          ]
        }
      ],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, emb_dim, n_heads, ff_mult=4, drop_rate=0.1, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(emb_dim)\n",
        "        self.attn = CausalSelfAttention(emb_dim, n_heads, drop_rate, qkv_bias)\n",
        "        self.ln2 = nn.LayerNorm(emb_dim)\n",
        "        self.ff = FeedForward(emb_dim, ff_mult, drop_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pre-LN style\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.ff(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class TinyGPT(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.tokpos = TokenPosEmbedding(config[\"vocab_size\"], config[\"emb_dim\"], config[\"context_length\"])\n",
        "        self.drop = nn.Dropout(config[\"drop_rate\"])\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(config[\"emb_dim\"], config[\"n_heads\"], ff_mult=4, drop_rate=config[\"drop_rate\"], qkv_bias=config[\"qkv_bias\"]) for _ in range(config[\"n_layers\"])])\n",
        "        self.ln_f = nn.LayerNorm(config[\"emb_dim\"])\n",
        "        # language modeling head tied to token embeddings (weight tying)\n",
        "        self.head = nn.Linear(config[\"emb_dim\"], config[\"vocab_size\"], bias=False)\n",
        "        # tie weights\n",
        "        self.head.weight = self.tokpos.token_emb.weight\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"\n",
        "        input_ids: (B, T) LongTensor\n",
        "        returns: logits (B, T, V)\n",
        "        \"\"\"\n",
        "        x = self.tokpos(input_ids)   # (B, T, C)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "        return logits\n",
        "\n",
        "# Build model using current config\n",
        "model_config = {\n",
        "    \"vocab_size\": VOCAB_SIZE,\n",
        "    \"context_length\": CTX_LEN,\n",
        "    \"emb_dim\": EMB_DIM,\n",
        "    \"n_heads\": N_HEADS,\n",
        "    \"n_layers\": N_LAYERS,\n",
        "    \"drop_rate\": DROP_RATE,\n",
        "    \"qkv_bias\": QKV_BIAS\n",
        "}\n",
        "\n",
        "model = TinyGPT(model_config)\n",
        "print(\"Model created. Parameter count:\", sum(p.numel() for p in model.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KVxhoUmbZSA",
        "outputId": "5be1f06b-0067-42b7-cbac-8188eb57534e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits shape: torch.Size([2, 512, 361])\n",
            "Dummy loss: 330.2403564453125\n"
          ]
        }
      ],
      "source": [
        "# Create random input batch (B, T)\n",
        "BATCH = 2\n",
        "SEQLEN = 512\n",
        "\n",
        "input_ids = torch.randint(0, VOCAB_SIZE, (BATCH, SEQLEN))\n",
        "with torch.no_grad():\n",
        "    logits = model(input_ids)\n",
        "print(\"Logits shape:\", logits.shape)   # expect (B, T, VOCAB_SIZE)\n",
        "\n",
        "# Compute a dummy loss (cross-entropy) on shifted targets for language modeling\n",
        "# Shift inputs by one for next-token prediction\n",
        "targets = torch.randint(0, VOCAB_SIZE, (BATCH, SEQLEN))\n",
        "loss_f = nn.CrossEntropyLoss()\n",
        "# Flatten logits and targets for loss: (B*T, V), (B*T)\n",
        "loss = loss_f(logits.view(-1, VOCAB_SIZE), targets.view(-1))\n",
        "print(\"Dummy loss:\", loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hj-Ic6BdDS1o"
      },
      "outputs": [],
      "source": [
        "# --- Encode / Decode using your BPE tokenizer and token2id ---\n",
        "\n",
        "def encode_sentence(sentence: str):\n",
        "    \"\"\"\n",
        "    Use your BPE tokenizer + token2id to convert a sentence to a list of token IDs.\n",
        "    \"\"\"\n",
        "    tokens = bpe_tokenize_sentence(sentence, merges)\n",
        "    ids = [token2id[tok] for tok in tokens if tok in token2id]\n",
        "    return ids\n",
        "\n",
        "def decode_ids(ids):\n",
        "    \"\"\"\n",
        "    Naive decode from IDs back to text using id2token.\n",
        "    This is approximate (BPE merges destroyed exact spacing),\n",
        "    but good enough to demo model outputs.\n",
        "    \"\"\"\n",
        "    tokens = [id2token.get(int(i), \"\") for i in ids]\n",
        "    # simple join; you can experiment with adding spaces\n",
        "    return \"\".join(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNGzBUY6DeJC",
        "outputId": "5f124d24-bcaa-4fbe-b89d-52387552a78b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building token ID corpus for train split...\n",
            "Train token ids: torch.Size([27632475])\n",
            "Final train_ids: torch.Size([24869227])\n",
            "Final val_ids:   torch.Size([2763248])\n"
          ]
        }
      ],
      "source": [
        "from itertools import islice\n",
        "import torch\n",
        "\n",
        "def build_token_id_corpus(split, text_key=text_key, max_samples=50_000):\n",
        "    \"\"\"\n",
        "    Turn a split (e.g., train) into one long tensor of token IDs.\n",
        "    We only use up to max_samples examples to keep it lightweight.\n",
        "    \"\"\"\n",
        "    all_ids = []\n",
        "    for i, text in enumerate(training_iterator(split, text_key=text_key)):\n",
        "        if i >= max_samples:\n",
        "            break\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)\n",
        "        encoded = encode_sentence(text)\n",
        "        if len(encoded) == 0:\n",
        "            continue\n",
        "        # Optionally, you can append a special EOS token if you have one;\n",
        "        # here we just concatenate the sequences.\n",
        "        all_ids.extend(encoded)\n",
        "    return torch.tensor(all_ids, dtype=torch.long)\n",
        "\n",
        "print(\"Building token ID corpus for train split...\")\n",
        "train_ids = build_token_id_corpus(train, text_key=text_key, max_samples=30_000)\n",
        "print(\"Train token ids:\", train_ids.shape)\n",
        "\n",
        "# Build a small validation set.\n",
        "# If dataset has 'test' split, use it; otherwise, slice from the end of train_ids.\n",
        "if \"test\" in ds:\n",
        "    print(\"Building token ID corpus for test split...\")\n",
        "    val_ids = build_token_id_corpus(ds[\"test\"], text_key=text_key, max_samples=5_000)\n",
        "else:\n",
        "    # last 10% of train_ids as validation\n",
        "    split_idx = int(0.9 * len(train_ids))\n",
        "    val_ids = train_ids[split_idx:].clone()\n",
        "    train_ids = train_ids[:split_idx].clone()\n",
        "\n",
        "print(\"Final train_ids:\", train_ids.shape)\n",
        "print(\"Final val_ids:  \", val_ids.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tSrNDPCDf9K"
      },
      "outputs": [],
      "source": [
        "# --- Batch generator for next-token prediction ---\n",
        "\n",
        "BLOCK_SIZE = min(128, CTX_LEN)  # keep <= CTX_LEN\n",
        "BATCH_SIZE = 512\n",
        "\n",
        "assert BLOCK_SIZE <= CTX_LEN, \"BLOCK_SIZE must be <= model context length\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "def get_batch(data_ids, batch_size=BATCH_SIZE, block_size=BLOCK_SIZE):\n",
        "    \"\"\"\n",
        "    Randomly sample a batch of subsequences from a 1D tensor of token IDs.\n",
        "    Returns x (input), y (targets) of shape (B, T).\n",
        "    \"\"\"\n",
        "    # ensure we have enough tokens\n",
        "    max_start = len(data_ids) - block_size - 1\n",
        "    ix = torch.randint(0, max_start, (batch_size,))\n",
        "    x = torch.stack([data_ids[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data_ids[i+1:i+block_size+1] for i in ix])\n",
        "    return x.to(device), y.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "YtkCLTlGDpuJ",
        "outputId": "cc381ea0-c880-484a-cd00-a583351e0646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step     1 | train loss: 317.3938 | val loss: 317.4657\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3946026264.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iters\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     loss = F.cross_entropy(logits.view(-1, VOCAB_SIZE),\n",
            "\u001b[0;32m/tmp/ipython-input-3970490140.py\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(data_ids, batch_size, block_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# --- Optimizer ---\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "\n",
        "def estimate_loss(eval_iters=20):\n",
        "    \"\"\"\n",
        "    Compute average loss on train & val for logging.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    out = {}\n",
        "    for split_name, data_ids in [(\"train\", train_ids), (\"val\", val_ids)]:\n",
        "        losses = []\n",
        "        for _ in range(eval_iters):\n",
        "            xb, yb = get_batch(data_ids)\n",
        "            with torch.no_grad():\n",
        "                logits = model(xb)\n",
        "                loss = F.cross_entropy(logits.view(-1, VOCAB_SIZE),\n",
        "                                       yb.view(-1))\n",
        "            losses.append(loss.item())\n",
        "        out[split_name] = sum(losses) / len(losses)\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "# --- Main training loop ---\n",
        "max_iters = 500   # you can increase if you have time/GPU\n",
        "log_interval = 50\n",
        "\n",
        "for step in range(1, max_iters + 1):\n",
        "    xb, yb = get_batch(train_ids)\n",
        "    logits = model(xb)\n",
        "    loss = F.cross_entropy(logits.view(-1, VOCAB_SIZE),\n",
        "                           yb.view(-1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % log_interval == 0 or step == 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"Step {step:5d} | train loss: {losses['train']:.4f} | val loss: {losses['val']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YrGupXJDuEj"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate_text(model, prompt, max_new_tokens=50, temperature=1.0, top_k=None):\n",
        "    \"\"\"\n",
        "    Autoregressively generate tokens from the model, starting from 'prompt'.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # Encode prompt to ids\n",
        "    prompt_ids = encode_sentence(prompt)\n",
        "    if len(prompt_ids) == 0:\n",
        "        raise ValueError(\"Prompt produced no tokens. Try a different prompt.\")\n",
        "    x = torch.tensor([prompt_ids], dtype=torch.long, device=device)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        # crop context if needed\n",
        "        if x.size(1) > CTX_LEN:\n",
        "            x_cond = x[:, -CTX_LEN:]\n",
        "        else:\n",
        "            x_cond = x\n",
        "\n",
        "        logits = model(x_cond)           # (B, T, V)\n",
        "        logits = logits[:, -1, :]        # (B, V) - last time step\n",
        "        if temperature != 1.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        if top_k is not None:\n",
        "            # keep only top_k probabilities\n",
        "            v, ix = torch.topk(probs, top_k)\n",
        "            probs = torch.zeros_like(probs).scatter_(1, ix, v)\n",
        "            probs = probs / probs.sum(dim=-1, keepdim=True)\n",
        "\n",
        "        next_id = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "        x = torch.cat([x, next_id], dim=1)\n",
        "\n",
        "    out_ids = x[0].tolist()\n",
        "    return decode_ids(out_ids)\n",
        "\n",
        "# Example generation\n",
        "prompt = \"भारत में शिक्षा\"\n",
        "print(\"PROMPT:\", prompt)\n",
        "print(\"GENERATED:\\n\", generate_text(model, prompt, max_new_tokens=60, temperature=0.9, top_k=20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv8UpNoSuPka"
      },
      "outputs": [],
      "source": [
        "def decode_ids(ids):\n",
        "    \"\"\"\n",
        "    Convert token IDs back to clean Hindi text without </w>.\n",
        "    \"\"\"\n",
        "    tokens = [id2token[i] for i in ids]\n",
        "\n",
        "    # Remove end-of-word markers\n",
        "    cleaned = [t.replace(\"</w>\", \"\") for t in tokens]\n",
        "\n",
        "    # Devanagari script does NOT use spaces between subword pieces,\n",
        "    # only between whole words. So we join by \"\" and then fix spacing.\n",
        "    text = \"\".join(cleaned)\n",
        "\n",
        "    # Put space between Hindi words using your rule:\n",
        "    # Insert space before tokens that originally ended with </w>.\n",
        "    # But since we stripped </w>, we need another trick:\n",
        "    # Your BPE tokens for Hindi alphabets usually start with a consonant/vowel.\n",
        "    # A simple heuristic: Add space before capital Latin tokens or digits.\n",
        "\n",
        "    # Simpler and safer: split using original tokens before cleaning\n",
        "    out_words = []\n",
        "    current_word = \"\"\n",
        "\n",
        "    for tok in tokens:\n",
        "        if tok.endswith(\"</w>\"):\n",
        "            tok_clean = tok.replace(\"</w>\", \"\")\n",
        "            current_word += tok_clean\n",
        "            out_words.append(current_word)\n",
        "            current_word = \"\"\n",
        "        else:\n",
        "            current_word += tok.replace(\"</w>\", \"\")\n",
        "\n",
        "    if current_word:\n",
        "        out_words.append(current_word)\n",
        "\n",
        "    return \" \".join(out_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvVx9MRyuSGG"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate_text(model, prompt, max_words=100, temperature=1.0, top_k=None):\n",
        "    model.eval()\n",
        "\n",
        "    # Encode\n",
        "    prompt_ids = encode_sentence(prompt)\n",
        "    x = torch.tensor([prompt_ids], dtype=torch.long, device=device)\n",
        "\n",
        "    generated_ids = prompt_ids.copy()\n",
        "\n",
        "    # We'll count words using decoded text\n",
        "    while True:\n",
        "        if len(generated_ids) > CTX_LEN:\n",
        "            x_cond = x[:, -CTX_LEN:]\n",
        "        else:\n",
        "            x_cond = x\n",
        "\n",
        "        logits = model(x_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "        logits = logits / temperature\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        if top_k:\n",
        "            top_vals, top_idx = torch.topk(probs, top_k)\n",
        "            probs = torch.zeros_like(probs).scatter_(1, top_idx, top_vals)\n",
        "            probs = probs / probs.sum(dim=-1, keepdim=True)\n",
        "\n",
        "        next_id = torch.multinomial(probs, num_samples=1).item()\n",
        "        generated_ids.append(next_id)\n",
        "\n",
        "        # update tensor\n",
        "        x = torch.tensor([generated_ids], dtype=torch.long, device=device)\n",
        "\n",
        "        # Check word count\n",
        "        decoded = decode_ids(generated_ids)\n",
        "        if len(decoded.split()) >= max_words:\n",
        "            break\n",
        "\n",
        "    return decoded"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "035e583f797b40e39954c4dc2c55ee6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78e18ad3555e4b8c971cd09d39711424",
            "placeholder": "​",
            "style": "IPY_MODEL_e9b354f11ae64b54be98a8cba9ba7100",
            "value": "data/train-00005-of-00006.parquet: 100%"
          }
        },
        "0a3c27cdf0f546afaac6997b67fc0d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1d777df70c649ce953cee61aad78053",
              "IPY_MODEL_382b2c65e51f41828ab5029b1390fbc7",
              "IPY_MODEL_f08c68002ba447b3bad4e0a7cc358d5d"
            ],
            "layout": "IPY_MODEL_142460aa15a447fd9e4781cc6615e8ec"
          }
        },
        "142460aa15a447fd9e4781cc6615e8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15081eaad9644578a0d52336473f2e18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a8735f13444025a4aa46f08d5f0ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_035e583f797b40e39954c4dc2c55ee6a",
              "IPY_MODEL_4705049a197f4407aa3b1ab77cbabf80",
              "IPY_MODEL_e48248dce0da4f9da2f13e5dd6c8195e"
            ],
            "layout": "IPY_MODEL_b7b7cee021b24dae942aecd5ae00db14"
          }
        },
        "2e8549966b534b9692d7da99f290fd34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382b2c65e51f41828ab5029b1390fbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cfd55b1fcf04440b8dde7dfe09a2289",
            "max": 601628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf3f0d3ab91d4def8f1b3e45e84a9f02",
            "value": 601628
          }
        },
        "3f44aaad56c3460ebaaace0af970cbf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fdddf7445e945aab0578d0d990b1dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4705049a197f4407aa3b1ab77cbabf80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15081eaad9644578a0d52336473f2e18",
            "max": 169367148,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2f3ef8df2814efe85683557aad37409",
            "value": 169367148
          }
        },
        "6cfd55b1fcf04440b8dde7dfe09a2289": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e18ad3555e4b8c971cd09d39711424": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f668f3bbfa845918e3418215ca6edf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f0e7ea07744469cb14847ebf9d64f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7b7cee021b24dae942aecd5ae00db14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cafb64776dab418fa27eae0d8ef835ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf3f0d3ab91d4def8f1b3e45e84a9f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e48248dce0da4f9da2f13e5dd6c8195e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cafb64776dab418fa27eae0d8ef835ca",
            "placeholder": "​",
            "style": "IPY_MODEL_3f44aaad56c3460ebaaace0af970cbf3",
            "value": " 169M/169M [00:02&lt;00:00, 90.8MB/s]"
          }
        },
        "e9b354f11ae64b54be98a8cba9ba7100": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f08c68002ba447b3bad4e0a7cc358d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f668f3bbfa845918e3418215ca6edf6",
            "placeholder": "​",
            "style": "IPY_MODEL_3fdddf7445e945aab0578d0d990b1dfa",
            "value": " 601628/601628 [00:23&lt;00:00, 48482.17 examples/s]"
          }
        },
        "f1d777df70c649ce953cee61aad78053": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e8549966b534b9692d7da99f290fd34",
            "placeholder": "​",
            "style": "IPY_MODEL_8f0e7ea07744469cb14847ebf9d64f62",
            "value": "Generating train split: 100%"
          }
        },
        "f2f3ef8df2814efe85683557aad37409": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}